{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "infrared-recording",
   "metadata": {},
   "source": [
    "# vectorizing job offers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-acquisition",
   "metadata": {},
   "source": [
    "## aim\n",
    "- cluster job offeres by similarity based on a dictionary of skills\n",
    "\n",
    "## outline\n",
    "- preprocess doc2vec with full job offers\n",
    "- train model\n",
    "- test similarity of job descriptions\n",
    "- cluster offers (Kmeans, KNN)\n",
    "\n",
    "## outcome\n",
    "unicorns in a meadow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "composite-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gensim\n",
    "import joblib\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from pprint import pprint\n",
    "import math\n",
    "import multiprocessing\n",
    "import gensim.models.doc2vec\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "proprietary-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = joblib.load('../../../raw_data/processed_data.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "mineral-blake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7859, 14)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "molecular-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tag_language'] = df['tag_language'].fillna(value='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "polish-chocolate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_text</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>job_info</th>\n",
       "      <th>query_text</th>\n",
       "      <th>source</th>\n",
       "      <th>job_link</th>\n",
       "      <th>tag_language</th>\n",
       "      <th>reviews</th>\n",
       "      <th>job_info_tokenized</th>\n",
       "      <th>job_text_tokenized</th>\n",
       "      <th>job_text_tokenized_titlecase</th>\n",
       "      <th>job_title_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Junior) Data Engineer (f/m/x)</td>\n",
       "      <td>Customlytics ist die führende App Marketing Be...</td>\n",
       "      <td>Customlytics GmbH</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>(Junior) Data Engineer (f/m/x)\\nCustomlytics G...</td>\n",
       "      <td>data science</td>\n",
       "      <td>scrape_json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[junior, data, engineer, fmx, customlytics, gm...</td>\n",
       "      <td>[customlytics, ist, die, führende, app, market...</td>\n",
       "      <td>[Customlytics, ist, die, führende, App, Market...</td>\n",
       "      <td>[junior, data, engineer, fmx]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Responsibilities\\n\\nAs working student (m/f/x)...</td>\n",
       "      <td>Aroundhome</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Aroundhome6 Bewertungen - Berlin</td>\n",
       "      <td>data science</td>\n",
       "      <td>scrape_json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[aroundhome, bewertungen, berlin]</td>\n",
       "      <td>[responsibilities, as, working, student, mfx, ...</td>\n",
       "      <td>[Responsibilities, As, working, student, mfx, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Aufgaben\\nAls Werkstudent (m/w/d) IT arbeitest...</td>\n",
       "      <td>Aroundhome</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Aroundhome6 Bewertungen - Berlin\\nTeilzeit, Pr...</td>\n",
       "      <td>data science</td>\n",
       "      <td>scrape_json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[aroundhome, bewertungen, berlin, teilzeit, pr...</td>\n",
       "      <td>[aufgaben, als, werkstudent, mwd, it, arbeites...</td>\n",
       "      <td>[Aufgaben, Als, Werkstudent, mwd, IT, arbeites...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        job_title  \\\n",
       "0  (Junior) Data Engineer (f/m/x)   \n",
       "1                                   \n",
       "2                                   \n",
       "\n",
       "                                            job_text            company  \\\n",
       "0  Customlytics ist die führende App Marketing Be...  Customlytics GmbH   \n",
       "1  Responsibilities\\n\\nAs working student (m/f/x)...         Aroundhome   \n",
       "2  Aufgaben\\nAls Werkstudent (m/w/d) IT arbeitest...         Aroundhome   \n",
       "\n",
       "  location                                           job_info    query_text  \\\n",
       "0   Berlin  (Junior) Data Engineer (f/m/x)\\nCustomlytics G...  data science   \n",
       "1   Berlin                   Aroundhome6 Bewertungen - Berlin  data science   \n",
       "2   Berlin  Aroundhome6 Bewertungen - Berlin\\nTeilzeit, Pr...  data science   \n",
       "\n",
       "        source job_link tag_language  reviews  \\\n",
       "0  scrape_json      NaN           en      NaN   \n",
       "1  scrape_json      NaN           en      NaN   \n",
       "2  scrape_json      NaN           de      NaN   \n",
       "\n",
       "                                  job_info_tokenized  \\\n",
       "0  [junior, data, engineer, fmx, customlytics, gm...   \n",
       "1                  [aroundhome, bewertungen, berlin]   \n",
       "2  [aroundhome, bewertungen, berlin, teilzeit, pr...   \n",
       "\n",
       "                                  job_text_tokenized  \\\n",
       "0  [customlytics, ist, die, führende, app, market...   \n",
       "1  [responsibilities, as, working, student, mfx, ...   \n",
       "2  [aufgaben, als, werkstudent, mwd, it, arbeites...   \n",
       "\n",
       "                        job_text_tokenized_titlecase  \\\n",
       "0  [Customlytics, ist, die, führende, App, Market...   \n",
       "1  [Responsibilities, As, working, student, mfx, ...   \n",
       "2  [Aufgaben, Als, Werkstudent, mwd, IT, arbeites...   \n",
       "\n",
       "             job_title_tokenized  \n",
       "0  [junior, data, engineer, fmx]  \n",
       "1                             []  \n",
       "2                             []  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "certain-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select english jobs\n",
    "df_eng = df.copy()\n",
    "df_eng = df_eng[df_eng['tag_language'] == 'en']\n",
    "df_eng.reset_index(inplace=True)\n",
    "df_eng.drop(columns='index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "animal-proposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_text</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>job_info</th>\n",
       "      <th>query_text</th>\n",
       "      <th>source</th>\n",
       "      <th>job_link</th>\n",
       "      <th>tag_language</th>\n",
       "      <th>reviews</th>\n",
       "      <th>job_info_tokenized</th>\n",
       "      <th>job_text_tokenized</th>\n",
       "      <th>job_text_tokenized_titlecase</th>\n",
       "      <th>job_title_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Junior) Data Engineer (f/m/x)</td>\n",
       "      <td>Customlytics ist die führende App Marketing Be...</td>\n",
       "      <td>Customlytics GmbH</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>(Junior) Data Engineer (f/m/x)\\nCustomlytics G...</td>\n",
       "      <td>data science</td>\n",
       "      <td>scrape_json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[junior, data, engineer, fmx, customlytics, gm...</td>\n",
       "      <td>[customlytics, ist, die, führende, app, market...</td>\n",
       "      <td>[Customlytics, ist, die, führende, App, Market...</td>\n",
       "      <td>[junior, data, engineer, fmx]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Responsibilities\\n\\nAs working student (m/f/x)...</td>\n",
       "      <td>Aroundhome</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Aroundhome6 Bewertungen - Berlin</td>\n",
       "      <td>data science</td>\n",
       "      <td>scrape_json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[aroundhome, bewertungen, berlin]</td>\n",
       "      <td>[responsibilities, as, working, student, mfx, ...</td>\n",
       "      <td>[Responsibilities, As, working, student, mfx, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Full Stack Developer (m/f/d)</td>\n",
       "      <td>We’re Phiture: a leading mobile growth consult...</td>\n",
       "      <td>Phiture</td>\n",
       "      <td>BerlinKreuzberg</td>\n",
       "      <td>Full Stack Developer (m/f/d)\\nPhiture - Berlin...</td>\n",
       "      <td>data science</td>\n",
       "      <td>scrape_json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[full, stack, developer, mfd, phiture, berlink...</td>\n",
       "      <td>[were, phiture, a, leading, mobile, growth, co...</td>\n",
       "      <td>[Were, Phiture, a, leading, mobile, growth, co...</td>\n",
       "      <td>[full, stack, developer, mfd]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>We are 18,000+ employees strong, operating in ...</td>\n",
       "      <td>PRA Health Sciences</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>PRA Health Sciences - Berlin</td>\n",
       "      <td>data science</td>\n",
       "      <td>scrape_json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[pra, health, sciences, berlin]</td>\n",
       "      <td>[we, are, employees, strong, operating, in, mo...</td>\n",
       "      <td>[We, are, employees, strong, operating, in, mo...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Head of Finance</td>\n",
       "      <td>Head of Finance (m/f/d)\\nAt Home our mission i...</td>\n",
       "      <td>Home HT GmbH</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Head of Finance\\nHome HT GmbH2 Bewertungen - B...</td>\n",
       "      <td>data science</td>\n",
       "      <td>scrape_json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[head, of, finance, home, ht, gmbh, bewertunge...</td>\n",
       "      <td>[head, of, finance, mfd, at, home, our, missio...</td>\n",
       "      <td>[Head, of, Finance, mfd, At, Home, our, missio...</td>\n",
       "      <td>[head, of, finance]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        job_title  \\\n",
       "0  (Junior) Data Engineer (f/m/x)   \n",
       "1                                   \n",
       "2    Full Stack Developer (m/f/d)   \n",
       "3                                   \n",
       "4                 Head of Finance   \n",
       "\n",
       "                                            job_text              company  \\\n",
       "0  Customlytics ist die führende App Marketing Be...    Customlytics GmbH   \n",
       "1  Responsibilities\\n\\nAs working student (m/f/x)...           Aroundhome   \n",
       "2  We’re Phiture: a leading mobile growth consult...              Phiture   \n",
       "3  We are 18,000+ employees strong, operating in ...  PRA Health Sciences   \n",
       "4  Head of Finance (m/f/d)\\nAt Home our mission i...         Home HT GmbH   \n",
       "\n",
       "          location                                           job_info  \\\n",
       "0           Berlin  (Junior) Data Engineer (f/m/x)\\nCustomlytics G...   \n",
       "1           Berlin                   Aroundhome6 Bewertungen - Berlin   \n",
       "2  BerlinKreuzberg  Full Stack Developer (m/f/d)\\nPhiture - Berlin...   \n",
       "3           Berlin                       PRA Health Sciences - Berlin   \n",
       "4           Berlin  Head of Finance\\nHome HT GmbH2 Bewertungen - B...   \n",
       "\n",
       "     query_text       source job_link tag_language  reviews  \\\n",
       "0  data science  scrape_json      NaN           en      NaN   \n",
       "1  data science  scrape_json      NaN           en      NaN   \n",
       "2  data science  scrape_json      NaN           en      NaN   \n",
       "3  data science  scrape_json      NaN           en      NaN   \n",
       "4  data science  scrape_json      NaN           en      NaN   \n",
       "\n",
       "                                  job_info_tokenized  \\\n",
       "0  [junior, data, engineer, fmx, customlytics, gm...   \n",
       "1                  [aroundhome, bewertungen, berlin]   \n",
       "2  [full, stack, developer, mfd, phiture, berlink...   \n",
       "3                    [pra, health, sciences, berlin]   \n",
       "4  [head, of, finance, home, ht, gmbh, bewertunge...   \n",
       "\n",
       "                                  job_text_tokenized  \\\n",
       "0  [customlytics, ist, die, führende, app, market...   \n",
       "1  [responsibilities, as, working, student, mfx, ...   \n",
       "2  [were, phiture, a, leading, mobile, growth, co...   \n",
       "3  [we, are, employees, strong, operating, in, mo...   \n",
       "4  [head, of, finance, mfd, at, home, our, missio...   \n",
       "\n",
       "                        job_text_tokenized_titlecase  \\\n",
       "0  [Customlytics, ist, die, führende, App, Market...   \n",
       "1  [Responsibilities, As, working, student, mfx, ...   \n",
       "2  [Were, Phiture, a, leading, mobile, growth, co...   \n",
       "3  [We, are, employees, strong, operating, in, mo...   \n",
       "4  [Head, of, Finance, mfd, At, Home, our, missio...   \n",
       "\n",
       "             job_title_tokenized  \n",
       "0  [junior, data, engineer, fmx]  \n",
       "1                             []  \n",
       "2  [full, stack, developer, mfd]  \n",
       "3                             []  \n",
       "4            [head, of, finance]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cosmetic-dealer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7547, 14)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "delayed-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join strings\n",
    "def join_strings(text):\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "excited-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize\n",
    "def lemmatize_words(word):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = lemmatizer.lemmatize(word)\n",
    "\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "medium-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "def remove_stopwords(text):\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text) \n",
    "    text = [w for w in word_tokens if not w in stop_words] \n",
    "  \n",
    "    return text\n",
    "\n",
    "#['heute', 'weiter', 'zur', 'bewerbung', 'diesen', 'job', 'melden']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "characteristic-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process text\n",
    "df_eng['clean'] = df_eng['job_text_tokenized'].apply(join_strings).apply(lemmatize_words)\\\n",
    "    .apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-accessory",
   "metadata": {},
   "source": [
    "## model doc2vec 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-brazilian",
   "metadata": {},
   "source": [
    "Conclusions :)\n",
    "- ~ 700 offers - 100 epocs\n",
    "    - model performs ok, but tends to cluster according to company\n",
    "    - texts with very high similarity (> 0.90) are likely to be duplicated job adds\n",
    "    - looks like the model first shows offers based on duplicates, then company, then position (probably because of semantics)\n",
    "\n",
    "\n",
    "- 2500 offers - 150 epocs\n",
    "    - still clusters by company\n",
    "    - add more data? or try bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ancient-volleyball",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['customlytics', 'ist', 'die', 'führende', 'app', 'marketing', 'beratungsagentur', 'aus', 'berlin', 'wir', 'bieten', 'consulting', 'und', 'handson', 'support', 'rund', 'um', 'app', 'marketing', 'strategie', 'produktmanagement', 'analytics', 'crm', 'unser', 'team', 'erarbeitet', 'mit', 'unternehmen', 'jeder', 'größe', 'konzepte', 'zur', 'erfolgreichen', 'vermarktung', 'von', 'mobilen', 'apps', 'dabei', 'decken', 'wir', 'nicht', 'nur', 'das', 'gesamte', 'spektrum', 'infrastruktureller', 'marketingthemen', 'ab', 'wir', 'konzipieren', 'planen', 'und', 'steuern', 'sowohl', 'das', 'ui', 'ux', 'design', 'von', 'mobilen', 'apps', 'als', 'auch', 'performance', 'marketing', 'kampagnen', 'für', 'alle', 'app', 'verticals', 'über', 'uns', 'unser', 'data', 'team', 'braucht', 'unterstützung', 'du', 'bist', 'motiviert', 'und', 'von', 'der', 'mobile', 'industry', 'begeistert', 'dann', 'suchen', 'wir', 'dich', 'um', 'die', 'data', 'warehouselösungen', 'für', 'unsere', 'kunden', 'aus', 'der', 'app', 'industrie', 'zu', 'entwickeln', 'und', 'implementieren', 'zusammen', 'mit', 'unserem', 'biteam', 'arbeitest', 'du', 'kundenprojekten', 'der', 'entwicklung', 'implementierung', 'und', 'optimierung', 'von', 'data', 'warehouse', 'projekten', 'du', 'arbeitest', 'hierbei', 'eng', 'mit', 'unserem', 'big', 'data', 'engineer', 'und', 'data', 'analyst', 'zusammen', 'der', 'entwicklung', 'von', 'dashboards', 'und', 'data', 'visualisierungen', 'talent', 'technologieaffinität', 'und', 'eigenverantwortung', 'für', 'deine', 'arbeit', 'zu', 'übernehmen', 'sind', 'die', 'basis', 'unserer', 'teamkultur', 'für', 'uns', 'ist', 'es', 'zweitrangig', 'ob', 'du', 'erst', 'anfang', 'deiner', 'beruflichen', 'laufbahn', 'stehst', 'oder', 'bereits', 'mehrjährige', 'berufserfahrung', 'hast', 'der', 'spirit', 'und', 'die', 'motivation', 'zählen', 'deine', 'aufgaben', 'du', 'berätst', 'unsere', 'teams', 'hinsichtlich', 'der', 'datenanforderungen', 'und', 'bist', 'die', 'schnittstelle', 'zwischen', 'marketingprodukt', 'consultants', 'und', 'dem', 'data', 'engineering', 'bi', 'team', 'du', 'unterstützt', 'bei', 'der', 'analyse', 'von', 'datenströmen', 'unserer', 'kunden', 'aus', 'der', 'mobilen', 'app', 'branche', 'dem', 'aufbereiten', 'von', 'daten', 'und', 'dem', 'entwickeln', 'von', 'datenmodellen', 'du', 'unterstützt', 'unser', 'consultingteam', 'und', 'interne', 'abteilungen', 'als', 'experte', 'bei', 'der', 'vorverarbeitung', 'und', 'auswertung', 'großer', 'datenmengen', 'du', 'versetzt', 'dich', 'die', 'lage', 'deiner', 'externen', 'und', 'internen', 'stakeholder', 'verstehst', 'ihre', 'ziele', 'und', 'anforderungen', 'und', 'übersetzt', 'diese', 'lösungen', 'entwicklung', 'von', 'data', 'warehousingprodukten', 'die', 'unseren', 'wettbewerbsvorteil', 'langfristig', 'sichern', 'und', 'ausbauen', 'dein', 'profil', 'du', 'arbeitet', 'gerne', 'auf', 'englisch', 'mit', 'internationalen', 'kolleginnen', 'du', 'hast', 'erste', 'erfahrung', 'im', 'data', 'oder', 'bo', 'bereich', 'und', 'hast', 'ein', 'abgeschlossenes', 'studium', 'im', 'bereich', 'information', 'systems', 'analytics', 'wirtschaftsinformatik', 'mathematik', 'oder', 'statistik', 'mit', 'affinität', 'zu', 'betriebswirtschaftlichen', 'themen', 'wie', 'zb', 'online', 'marketing', 'du', 'begeisterst', 'dich', 'für', 'die', 'mobile', 'apptechnologiebranche', 'und', 'hast', 'großes', 'interesse', 'technischen', 'lösungen', 'und', 'wie', 'apps', 'unter', 'der', 'haube', 'funktionieren', 'basiswissen', 'sql', 'python', 'und', 'git', 'grundkenntnisse', 'redshift', 'undoder', 'bigquery', 'routinierter', 'umgang', 'mit', 'gängigen', 'anwendungen', 'wie', 'google', 'drive', 'microsoft', 'office', 'mac', 'os', 'und', 'keine', 'scheu', 'sich', 'schnell', 'verschiedene', 'projektmanagement', 'analyse', 'und', 'marketingtools', 'einzuarbeiten', 'du', 'überzeugst', 'mit', 'proaktivität', 'und', 'lösungsorientierter', 'denkweise', 'bonus', 'points', 'agentur', 'undoder', 'startup', 'erfahrung', 'erste', 'erfahrungen', 'mit', 'reporting', 'tools', 'wie', 'google', 'data', 'studio', 'und', 'der', 'google', 'cloud', 'platform', 'aws', 'wir', 'bieten', 'mehr', 'als', 'app', 'store', 'optimization', 'wir', 'sind', 'die', 'einzige', 'fullstack', 'beratungsagentur', 'im', 'deutschen', 'raum', 'und', 'beraten', 'kunden', 'zu', 'vielfältigen', 'app', 'marketing', 'produktmanagement', 'und', 'analytics', 'themen', 'bvg', 'jobticket', 'für', 'den', 'ab', 'bereich', 'highend', 'hardware', 'die', 'du', 'für', 'deine', 'perfekte', 'arbeitsumgebung', 'im', 'büro', 'und', 'remote', 'benötigst', 'frei', 'verfügbare', 'anzahl', 'von', 'remote', 'work', 'tagen', 'ob', 'du', 'im', 'büro', 'arbeitest', 'oder', 'woanders', 'produktiver', 'bist', 'es', 'dir', 'selbst', 'aus', 'early', 'bird', 'oder', 'eule', 'flexible', 'arbeitszeiten', 'erlauben', 'es', 'dir', 'deine', 'arbeitszeit', 'individuell', 'zu', 'planen', 'regelmäßige', 'learning', 'sessions', 'mit', 'unserem', 'team', 'und', 'branchenexperten', 'sichern', 'dir', 'eine', 'steile', 'lernkurve', 'und', 'stetige', 'weiterentwicklung', 'smoothes', 'onboarding', 'mit', 'unserem', 'buddy', 'system', 'neben', 'dem', 'obligatorischen', 'müsli', 'haben', 'wir', 'eine', 'pastapesto', 'flatrate', 'im', 'büro', 'startupmentalität', 'findest', 'du', 'bei', 'uns', 'natürlich', 'auch', 'aber', 'mit', 'der', 'nötigen', 'vision', 'und', 'professionalität', 'um', 'zum', 'marktführer', 'unter', 'den', 'beratungsunternehmen', 'europa', 'zu', 'werden', 'die', 'sich', 'auf', 'mobile', 'marketing', 'spezialisiert', 'haben', 'gute', 'performance', 'und', 'drive', 'werden', 'bei', 'uns', 'belohnt', 'und', 'führen', 'zu', 'kompetitiven', 'gehältern', 'über', 'dem', 'branchendurchschnitt', 'ein', 'motiviertes', 'team', 'mit', 'flachen', 'hierarchien', 'regelmäßig', 'stattfindende', 'team', 'events', 'und', 'company', 'offsites', 'nimm', 'unseren', 'meetups', 'teil', 'und', 'vernetze', 'dich', 'mit', 'berlins', 'mobiler', 'marketing', 'startup', 'szene', 'junior', 'data', 'engineer', 'fmx', 'role', 'junior', 'data', 'engineer', 'responsible', 'improving', 'maintaining', 'data', 'warehouse', 'solutions', 'developing', 'implementing', 'data', 'warehouse', 'solutions', 'clients', 'working', 'within', 'business', 'intelligence', 'team', 'data', 'bi', 'analyst', 'big', 'data', 'engineer', 'act', 'point', 'contact', 'clients', 'projects', 'evolved', 'upon', 'joining', 'get', 'know', 'customlytics', 'services', 'clients', 'getting', 'sense', 'headed', 'familiarise', 'quickly', 'expected', 'roll', 'sleeves', 'take', 'action', 'addition', 'working', 'friendly', 'modern', 'work', 'atmosphere', 'right', 'prenzlauer', 'berg', 'one', 'liveliest', 'central', 'places', 'berlin', 'responsibilities', 'support', 'area', 'data', 'engineering', 'enable', 'team', 'focus', 'delivering', 'insights', 'clients', 'app', 'businesses', 'consult', 'teams', 'data', 'needs', 'serve', 'liaison', 'marketingproduct', 'teams', 'data', 'engineering', 'team', 'responsible', 'providing', 'insightful', 'data', 'deep', 'dives', 'analytical', 'assistance', 'clientfacing', 'business', 'development', 'accounting', 'teams', 'understand', 'challenges', 'clients', 'facing', 'today', 'tomorrow', 'analyzing', 'trends', 'clients', 'data', 'providing', 'insight', 'explanation', 'improve', 'operations', 'run', 'ad', 'hoc', 'analysis', 'build', 'data', 'visualizations', 'continue', 'developing', 'clients', 'data', 'warehouse', 'infrastructure', 'data', 'engineering', 'team', 'help', 'foster', 'datadriven', 'culture', 'throughout', 'whole', 'team', 'apply', 'best', 'practices', 'profile', 'gained', 'first', 'experiences', 'data', 'bi', 'field', 'degree', 'related', 'field', 'like', 'information', 'systems', 'analytics', 'economics', 'computer', 'science', 'statistics', 'another', 'similar', 'quantitative', 'field', 'techsavvy', 'enthusiastic', 'mobile', 'industry', 'fluent', 'english', 'working', 'englishspeaking', 'team', 'sound', 'good', 'great', 'analytical', 'skills', 'ability', 'make', 'reasonable', 'use', 'data', 'working', 'clients', 'first', 'knowledge', 'sql', 'python', 'familiar', 'git', 'basic', 'knowledge', 'redshift', 'andor', 'bigquery', 'plus', 'businessminded', 'passionate', 'diving', 'making', 'sense', 'large', 'diverse', 'datasets', 'bonus', 'points', 'agency', 'experience', 'german', 'language', 'skills', 'knowledge', 'reporting', 'tools', 'like', 'google', 'data', 'studio', 'knowledge', 'google', 'cloud', 'platform', 'aws', 'ecosystem', 'offer', 'app', 'store', 'optimization', 'fullstack', 'consulting', 'agency', 'germany', 'advise', 'clients', 'wide', 'range', 'app', 'marketing', 'product', 'management', 'analytics', 'topics', 'bvg', 'job', 'ticket', 'ab', 'area', 'highend', 'hardware', 'need', 'perfect', 'working', 'environment', 'office', 'remote', 'unlimited', 'number', 'remote', 'workdays', 'whether', 'work', 'office', 'productive', 'somewhere', 'else', 'choose', 'early', 'bird', 'owl', 'flexible', 'working', 'hours', 'allow', 'plan', 'working', 'time', 'individually', 'regular', 'learning', 'sessions', 'team', 'industry', 'experts', 'ensure', 'steep', 'learning', 'curve', 'continuous', 'development', 'smooth', 'onboarding', 'buddy', 'system', 'addition', 'obligatory', 'muesli', 'pastapesto', 'flat', 'rate', 'office', 'course', 'also', 'find', 'startup', 'mentality', 'us', 'necessary', 'vision', 'professionalism', 'become', 'market', 'leader', 'among', 'consultancies', 'europe', 'specializing', 'mobile', 'marketing', 'good', 'performance', 'drive', 'rewarded', 'us', 'lead', 'competitive', 'salaries', 'industry', 'average', 'motivated', 'team', 'flat', 'hierarchies', 'regular', 'team', 'events', 'company', 'offsites', 'take', 'part', 'meetups', 'network', 'berlins', 'mobile', 'marketing', 'startup', 'scene', 'vertragsdauer', 'monate', 'art', 'der', 'stelle', 'vollzeit', 'befristet', 'arbeitszeiten', 'keine', 'wochenenden', 'montag', 'bis', 'freitag', 'leistungen', 'betriebliche', 'altersvorsorge', 'betriebliche', 'weiterbildung', 'flexible', 'arbeitszeiten', 'homeoffice', 'kostenlose', 'getränke', 'kostenloses', 'oder', 'vergünstigtes', 'essen', 'berufserfahrung', 'aws', 'jahr', 'bevorzugt', 'sql', 'jahr', 'bevorzugt', 'google', 'data', 'studio', 'jahr', 'bevorzugt', 'homeoffice', 'ja', 'gerade', 'geschaltet', 'diesen', 'job', 'melden'], tags=['tag_0'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag texts\n",
    "texts = df_eng['clean']\n",
    "texts_tagged = [TaggedDocument(text, tags=['tag_'+str(tag)]) for tag, text in enumerate(texts)]\n",
    "texts_tagged[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "inclusive-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduced dataset\n",
    "texts_tagged_small = texts_tagged[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "innocent-brick",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_to_train = texts_tagged_small # texts_tagged_small, texts_tagged\n",
    "\n",
    "# build vocabulary with CBOW (dm=0)\n",
    "cores = multiprocessing.cpu_count()\n",
    "model_dbow = Doc2Vec(documents=data_to_train,\n",
    "                     dm=0,\n",
    "                     alpha=0.025,\n",
    "                     vector_size=len(data_to_train), \n",
    "                     min_count=1,\n",
    "                     workers=cores)\n",
    "\n",
    "# train the model\n",
    "model_dbow.train(data_to_train, total_examples=model_dbow.corpus_count, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "desirable-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow.save('../../../models/doc2vec_3000_15_epochs')\n",
    "#joblib.dump(model_dbow, filename='../../../models/doc2vec_3000_20_epochs.joblib' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow.corpus_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-winner",
   "metadata": {},
   "source": [
    "### test the model by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "capable-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_loaded = Doc2Vec.load('../../../models/doc2vec_3000_20_epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "optional-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_jobs(tokenized_job, offers):\n",
    "    ''' input: tokenized job offers, number of offers \n",
    "        returns tags of top x most similar job offers and similarity probabilities\n",
    "    '''\n",
    "\n",
    "    # infer vector from text \n",
    "    infer_vector = model_loaded.infer_vector(tokenized_job)\n",
    "    # find similar offers\n",
    "    similar_documents = model_loaded.docvecs.most_similar([infer_vector], topn = offers)\n",
    "\n",
    "    return similar_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "decreased-london",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_jobs(text_index, offers=5):\n",
    "    \n",
    "    \"\"\" input: index of text in dataframe and number of offers we want to see\n",
    "        prints text of the offers\n",
    "    \"\"\"\n",
    "    \n",
    "    tags = similar_jobs(texts[text_index], offers)\n",
    "    tags = [list(i) for i in tags]\n",
    "    \n",
    "    print(f\"{tags}\\n\")\n",
    "    print(f\"{df_eng['job_title'][text_index], df_eng['company'][text_index], df_eng['job_text'][text_index]} \\\n",
    "        \\n-------------END------------\\n \")\n",
    "    \n",
    "    for tag in tags: \n",
    "        num = int(tag[0].strip('tag_'))\n",
    "        \n",
    "        print(f\"{df_eng['job_title'][num], df_eng['company'][num], df_eng['job_text'][num]} \\\n",
    "        \\n-------------END------------\\n \") \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "radical-greeting",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['tag_400', 0.9450560808181763], ['tag_816', 0.7360695600509644], ['tag_385', 0.7156456708908081], ['tag_337', 0.4847617447376251], ['tag_476', 0.4800282120704651], ['tag_66', 0.4686710834503174], ['tag_452', 0.46127212047576904], ['tag_592', 0.45939743518829346], ['tag_149', 0.45668190717697144], ['tag_378', 0.45607903599739075]]\n",
      "\n",
      "('Senior Data Engineer - Lending Tribe', 'SumUp', \"The mission of SumUp's Lending Tribe is to provide our small merchants, who are often turned away by financial institutions, with access to capital to grow their businesses.\\nAs a Senior Data Engineer in this green-field tribe, you'll work with a cross-functional team to bring transparent, affordable and seamless lending products to millions of small merchants across our 30+ markets. You'll play a leading role in architecting and developing the lending risk platform to provide access to working capital to all of our small merchants while systematically mitigating business and fraud risks for SumUp's business.\\nWhat you'll do\\nArchitect and build the lending risk platform, a mission-critical system responsible to determine our merchants level of access to financial support. Accuracy, quality and uptime are paramount.\\nWork within a cross-functional team to deliver and evolve predictive models end-to-end.\\nDesign, build, and evolve systems and interfaces that enable your team with relevant, usable and reliable data (internal and external) to evolve the models used to predict lending risk.\\nDevelop interfaces and procedures to make lending risk decisions widely and seamlessly available to internal customers, enabling the financial viability and scalability of an array of financial products within SumUp.\\nWork with the data platform engineering team to develop data structures and reliable data pipelines.\\nDeepen your knowledge of machine learning methodologies such as feature engineering, ETL, training, validation and model deployment and monitoring\\nBecome an expert in Airflow, Kubernetes, Spark, Datarobot, Kafka and other technologies that make up parts of our production ML stack.\\nYou'll be great for this position if\\nYou have 5+ years of relevant experience building large scale data solutions to enable people and systems.\\nYou're an expert in data ingestion, scheduling and warehousing fundamentals.\\nYou have a variety of software development experience - you are proficient with practices like software design patterns, code review, multiple languages and paradigms, DDD, etc.\\nYour previous experience within the financial services and banking domain rounds your profile.\\nWhy you should join SumUp\\nWe have a dedicated annual budget for attending conferences and advancing your career through further education.\\nWe encourage you to speak at conferences and give talks.\\nJoin part of a growing Data Science community within SumUp.\\nYou'll attend a weekly Lunch and Learn session, where the local engineering team exchanges ideas over company-sponsored lunch.\\nWe set aside time biweekly for side-projects and open source initiatives.\\nYou'll attend annual hackathons with the engineering teams from Berlin, Cologne, Sofia and São Paulo.\\nYou'll be part of a close, welcoming and international community.\\nWe get together regularly for brunches, cocktail nights, football, office events, AMA sessions, training, German lessons and yoga classes.\\nWe offer numerous other benefits such as Urban Sports Club subsidy, corporate pension scheme, Kita placement assistance, relocation assistance, 2x per week subsidised office lunches, and a gorgeous place to work in the heart of Berlin at Alexanderplatz.\\nAbout SumUp\\nWe believe in the everyday hero.\\nSmall business owners are at the heart of all we do, so we create powerful, easy-to-use financial solutions to help them run their businesses. With a founder's mentality and a 'team-first' attitude, our diverse teams across Europe, South America and the United States work together to ensure that the small business owners we partner with can be successful doing what they love.\\nSumUp is an Equal Employment Opportunity employer that proudly pursues and hires a diverse workforce. SumUp does not make hiring or employment decisions on the basis of race, colour, religion or religious belief, ethnic or national origin, nationality, sex, gender, gender identity, sexual orientation, disability, age or any other basis protected by applicable laws or prohibited by company policy. SumUp also strives for a healthy and safe workplace and strictly prohibits harassment of any kind.\\nSumUp will not accept unsolicited resumes from any source other than directly from a candidate.\\nVor mehr als 30 Tagen\\n- Weiter zur Bewerbung\\nDiesen Job melden\")         \n",
      "-------------END------------\n",
      " \n",
      "('Senior Data Engineer - Lending Tribe', 'SumUp', \"The mission of SumUp's Lending Tribe is to provide our small merchants, who are often turned away by financial institutions, with access to capital to grow their businesses.\\nAs a Senior Data Engineer in this green-field tribe, you'll work with a cross-functional team to bring transparent, affordable and seamless lending products to millions of small merchants across our 30+ markets. You'll play a leading role in architecting and developing the lending risk platform to provide access to working capital to all of our small merchants while systematically mitigating business and fraud risks for SumUp's business.\\nWhat you'll do\\nArchitect and build the lending risk platform, a mission-critical system responsible to determine our merchants level of access to financial support. Accuracy, quality and uptime are paramount.\\nWork within a cross-functional team to deliver and evolve predictive models end-to-end.\\nDesign, build, and evolve systems and interfaces that enable your team with relevant, usable and reliable data (internal and external) to evolve the models used to predict lending risk.\\nDevelop interfaces and procedures to make lending risk decisions widely and seamlessly available to internal customers, enabling the financial viability and scalability of an array of financial products within SumUp.\\nWork with the data platform engineering team to develop data structures and reliable data pipelines.\\nDeepen your knowledge of machine learning methodologies such as feature engineering, ETL, training, validation and model deployment and monitoring\\nBecome an expert in Airflow, Kubernetes, Spark, Datarobot, Kafka and other technologies that make up parts of our production ML stack.\\nYou'll be great for this position if\\nYou have 5+ years of relevant experience building large scale data solutions to enable people and systems.\\nYou're an expert in data ingestion, scheduling and warehousing fundamentals.\\nYou have a variety of software development experience - you are proficient with practices like software design patterns, code review, multiple languages and paradigms, DDD, etc.\\nYour previous experience within the financial services and banking domain rounds your profile.\\nWhy you should join SumUp\\nWe have a dedicated annual budget for attending conferences and advancing your career through further education.\\nWe encourage you to speak at conferences and give talks.\\nJoin part of a growing Data Science community within SumUp.\\nYou'll attend a weekly Lunch and Learn session, where the local engineering team exchanges ideas over company-sponsored lunch.\\nWe set aside time biweekly for side-projects and open source initiatives.\\nYou'll attend annual hackathons with the engineering teams from Berlin, Cologne, Sofia and São Paulo.\\nYou'll be part of a close, welcoming and international community.\\nWe get together regularly for brunches, cocktail nights, football, office events, AMA sessions, training, German lessons and yoga classes.\\nWe offer numerous other benefits such as Urban Sports Club subsidy, corporate pension scheme, Kita placement assistance, relocation assistance, 2x per week subsidised office lunches, and a gorgeous place to work in the heart of Berlin at Alexanderplatz.\\nAbout SumUp\\nWe believe in the everyday hero.\\nSmall business owners are at the heart of all we do, so we create powerful, easy-to-use financial solutions to help them run their businesses. With a founder's mentality and a 'team-first' attitude, our diverse teams across Europe, South America and the United States work together to ensure that the small business owners we partner with can be successful doing what they love.\\nSumUp is an Equal Employment Opportunity employer that proudly pursues and hires a diverse workforce. SumUp does not make hiring or employment decisions on the basis of race, colour, religion or religious belief, ethnic or national origin, nationality, sex, gender, gender identity, sexual orientation, disability, age or any other basis protected by applicable laws or prohibited by company policy. SumUp also strives for a healthy and safe workplace and strictly prohibits harassment of any kind.\\nSumUp will not accept unsolicited resumes from any source other than directly from a candidate.\\nVor mehr als 30 Tagen\\n- Weiter zur Bewerbung\\nDiesen Job melden\")         \n",
      "-------------END------------\n",
      " \n",
      "('Senior Tech Recruiter (f, m, d) - Online Payments', 'SumUp', 'SumUp\\'s Online Payments tribe enables merchants to offer state-of-the-art payment solutions for their online businesses. This tribe plays a key role in working towards SumUp\\'s vision of operating a 360° full-cycle payments solution provider.\\nAs Senior Tech Recruiter, you\\'ll be a key contributor to the team\\'s overall success. You\\'ll take full ownership of hiring processes and constantly contribute to our journey from good to great. You\\'ll be the single point of contact to your hiring managers, driving initiatives to empower top tier teams for making our vision come true.\\n\\nWhat you\\'ll do\\nCollaborate with hiring managers in Engineering and Product to drive the end-to-end selection process and make hiring decisions together\\nEvaluate business needs, the state of the job market and local hiring practices in order to coach hiring teams on \"what good looks like\"\\nOwn talent attraction and engagement for your team from strategy to execution (e.g. job advertisement, sourcing, internal referral events etc.)\\nOptimise and develop the team and our processes, covering topics that vary from employer branding to candidate assessment, candidate experience, inclusion and Talent Acquisition metrics\\nInterview candidates combining various methods like structured interviews, technical assessments and behavioural questions\\nProvide an efficient, professional and high-quality experience for every candidate and hiring manager\\n\\nYOUR PROFILE\\nYou have a Bachelor\\'s degree in HR, economics, psychology or natural science and 3+ years full time work experience as Technical Recruiter in a fast paced tech environment. (onsite experience preferred)\\nYou think with the mind of a Talent Acquisition Partner and are used to take ownership.\\nYou have a passion for people, technology and economics.\\nYou\\'re skilled in and passionate about state of the art recruitment tools, skills and other operational activities.\\nYou\\'re an outstanding communicator, outcome-oriented, empathetic and courageous to think critically and challenge stakeholders. Intelligence, business maturity, energy and integrity will make you successful in this role.\\nYou\\'re fluent in English. - You\\'ll be part of a truly global team, additional languages would be considered a plus.\\n\\nWhy you should join SumUp\\nWe have a dedicated annual budget for attending conferences and advancing your career through further education. We encourage you to speak at conferences and give talks.\\nYou\\'ll attend a weekly Lunch and Learn session, where the local engineering team exchanges ideas over company-sponsored lunch.\\nWe set aside time every other week for side-projects and open source initiatives.\\nYou\\'ll attend annual hackathons with the engineering teams from Berlin, Cologne, Sofia and São Paulo.\\nYou\\'ll be part of a close, welcoming and international community. We get together regularly for brunches, cocktail nights, football, office events, AMA sessions, training, German lessons and yoga classes.\\nWe offer numerous other benefits such as Urban Sports Club subsidy, corporate pension scheme, Kita placement assistance, relocation assistance, 2x per week subsidised office lunches, and a gorgeous place to work in the heart of Berlin at Alexanderplatz.\\n\\nAbout SumUp\\nWe believe in the everyday hero.\\nSmall business owners are at the heart of all we do, so we\\'re creating powerful, easy-to-use financial solutions to help them run their businesses. With a founder\\'s mentality and a \\'team-first\\' attitude, our diverse teams across Europe, South America and the United States work together to ensure that small business owners can be successful doing what they love.\\nSumUp is an Equal Employment Opportunity employer that proudly pursues and hires a diverse workforce. SumUp does not make hiring or employment decisions on the basis of race, colour, religion or religious belief, ethnic or national origin, nationality, sex, gender, gender identity, sexual orientation, disability, age or any other basis protected by applicable laws or prohibited by company policy. SumUp also strives for a healthy and safe workplace and strictly prohibits harassment of any kind.\\nSumUp will not accept unsolicited resumes from any source other than directly from a candidate.\\nWant to get more insights about SumUp? Don\\'t miss to visit us on our blog on Medium, or check our social media pages on Facebook, Twitter and LinkedIn.\\nvor 5 Tagen\\n- Weiter zur Bewerbung\\nDiesen Job melden')         \n",
      "-------------END------------\n",
      " \n",
      "('Senior Frontend Engineer - Data / Platform', 'SumUp', \"As a Senior Frontend Engineer, you'll join the Onsite Tracking team, which is at the core of enabling SumUp to be a data-driven company. As the team is still forming, you'll have the opportunity to directly impact shaping the team's future.\\nYou'll be the technical owner of SumUp's open-source tracking and page performance libraries, ensuring that onsite data is collected, processed and then provided consistently and largely automated.\\n\\nWhat you'll do\\nTake over the technical ownership and development of SumUp's open-source tracking and page performance measurement libraries\\nCollaborate with engineering teams to further shape our open source libraries\\nDiscover new tracking opportunities (e.g. new browser APIs) as well as industry trends (e.g. tracking prevention measures and cookieless tracking)\\nMentor your fellow engineers\\nParticipate in team rituals\\nMake architectural decisions\\n\\nYou'll be great for this role if\\nYou have extensive experience with JavaScript, React, Node.JS\\nYou are comfortable with Docker\\nYou have great communication skills\\nYou have excellent coaching and mentoring skills\\n\\nIt would be a plus if\\nYou're experienced with Onsite Tracking Implementation (e.g. dataLayer design, integrating and debugging Google Analytics or other tracking services)\\nYou have solid infrastructure knowledge (Preferably AWS)\\nYou have experience with databases and ETL-processes\\n\\n\\nWhy you should join SumUp\\nWe're a truly global team of 2000+ people from 60+ countries, spread across 3 continents\\nWe get together regularly for breakfasts, team events, office parties and sports\\nYou'll receive a budget for attending conferences and external training\\nWe offer a corporate pension scheme, 28 days' paid leave, free German and yoga classes, subsidised Urban Sports Club membership and other great benefits\\nWe offer visa and relocation support for you, your family and even your pets\\nYou'll be based in the heart of Berlin, one of Europe's leading tech hubs and most vibrant cities\\nYou'll participate in weekly Lunch and Learn sessions, where ideas are shared and discussed over company-sponsored lunch\\nYou'll attend global offsites and/or hackathons\\n\\nAbout SumUp\\nWe believe in the everyday hero. Small business owners are at the heart of all we do, so we create powerful, easy-to-use financial solutions to help them run their businesses. With a founder's mentality and a 'team-first' attitude, our diverse teams across Europe, South America and the United States work together to ensure that the small business owners we partner with can be successful doing what they love.\\nSumUp is an Equal Employment Opportunity employer that proudly pursues and hires a diverse workforce. SumUp does not make hiring or employment decisions on the basis of race, colour, religion or religious belief, ethnic or national origin, nationality, sex, gender, gender identity, sexual orientation, disability, age or any other basis protected by applicable laws or prohibited by company policy. SumUp also strives for a healthy and safe workplace and strictly prohibits harassment of any kind.\\nSumUp will not accept unsolicited resumes from any source other than directly from a candidate.\\nvor 27 Tagen\\n- Weiter zur Bewerbung\\nDiesen Job melden\")         \n",
      "-------------END------------\n",
      " \n",
      "('Senior Data Engineer (f/m/x)', 'PPRO', 'You see Data as the bloodstream of modern technology and a nutrient substance behind business decisions revolutionizing our world. With your experience in automating the Cloud infrastructure for event streams, data pipelines and storage, it is always easy for you to make necessary changes to the configuration and ensure reliable application and user access to the data. Your desk will be located in Berlin, but your impact will be global.nbsp;Key responsibilities\\nAdministration, maintenance, and fine-tuning of Kafka clusters in high-availability mode.nbsp;\\nDesign and implementation of a data lake and data ingestion pipelines from various sources (SQL DBs, Kafka, Cassandra, logs, metrics, etc.)nbsp;\\nTaking part in architecting our event-driven platform.nbsp;\\nGuiding software engineers on best practices of using Kafka from the Data engineering perspective.nbsp;\\nEnabling BI developers to consume consolidated and prepared data.nbsp;\\nHelp with building a team of Data experts.nbsp;\\nQualifications\\nExpert level of running Kafka clusters.nbsp;\\nStrong experience with designing and running infrastructure in AWS.nbsp;\\nPractical experience with Kubernetes and Terraform.nbsp;\\nHands-on programming experience with either Python, Java, or Scala.nbsp;\\nStrong SQL abilities.nbsp;\\nAdministration of both SQL (MySQL/MariaDB) and no-SQL (Cassandra) databases.nbsp;\\nExperience with logging and monitoring tools.nbsp;\\nDemonstrable ability to clearly communicate and productively collaborate with others.nbsp;\\nWorking experience with agile implementation methodologies.nbsp;\\nWe’d love to see:That you like to challenge the status quo and that you drive change for the better. We love working with people that are great communicators and people who thrive in truly international environments.\\nAbout us: Most of the world’s e-commerce purchases are made with a local payment method, not a big-brand credit card. Yet most of the payments industry is card-centric; not many companies can accept the 500 different ways the world pays. That’s where PPRO comes in.nbsp;nbsp;PPRO focuses on local payments, all day, every day. While many Buzzword-as-a-Service companies try to be all things to all people, we painstakingly engineer our infrastructure to do one thing: help businesses accept payment across borders. And it pays off; our technology and services power international growth for companies like Citi, Mollie, PayPal, and Worldpay.nbsp;Speaking of growth, we just raised over $180 million in new investment to take PPRO to the next level. If you want to work at a company where every idea is heard, and there’s always a way to make an impact, let’s talk. If you like to work the way we do by building trust and driving change we want to hear from you.nbsp;nbsp;Our offices in Singapore, London, Munich, Cologne, Berlin, Luxembourg, Atlanta, San Franc\\n\\nApply Now at Mustakbil.com\\n\\nThis job was originally posted on Mustakbil.com\\nMustakbil\\nvor 5 Tagen\\n- Weiter zur Bewerbung\\nDiesen Job melden')         \n",
      "-------------END------------\n",
      " \n",
      "('Data Engineer, Data Platform', 'GetYourGuide', \"GetYourGuide is the place to book the best experiences in destinations across the globe. We are now looking for a full-time Data Engineer, Data Platform at our Berlin office.\\nYou will play a key role in designing and developing our data ecosystem, big data-pipelines, data tooling and processes. You will also help make the vast amount of our data accessible, reliable and efficient to query.\\nTeam Mission:\\nThe Data Platform team plays the central role in our data-driven strategy, designing and developing our data ecosystem, data processes and analytics capabilities. We work on problems such as product events tracking, AB experiments framework, and real-time streaming applications. The team is also responsible for making the vast amount of data accessible, reliable and efficient to query, so we are empowered to make the best data-driven decisions. We work with a wide variety of tools and technologies ranging from Spark, Airflow, and Kafka to Databricks, Looker and Snowflake, making this team a great place to learn new skills.\\nResponsibilities:\\nYou will design, build and refine our data and analytics infrastructure, scaling to petabytes of data\\nYou will grow our analytics capabilities with faster, more reliable data pipelines, and better tools\\nYou'll work together with Business Intelligence, Analytics, and the whole Engineering department to ensure high data quality\\nYou will design and develop a real-time events pipeline and work with data scientists, backend engineers and product managers to find new ways to leverage this data\\nYou will develop complex and efficient pipelines to transform raw data sources into powerful, reliable components of our data lake\\nYou will optimize and improve existing features or data processes for performance and stability\\nRequirements:\\nYou have 1-2 years of experience as a Data Engineer\\nYou have experience designing, developing and maintaining systems at scale\\nYou have strong experience with Scala or Java\\nYou have strong experience with big data technologies (e.g. Spark)\\nYou write efficient, well-tested code with an keen eye on scalability and maintainability\\nYou are familiar with agile development\\nYou have an analytical mind and bake your decisions with data\\nNice to have:\\nYou have experience with Python\\nYou have experience working with Airflow\\nYou have experience with AWS and cloud technologies\\nYou have experience with building stream-processing systems, using solutions such as Kafka and Spark Streaming\\nYou have experience with Microservice Architecture\\nWe Offer:\\nWork on a product that helps create memorable travel experiences\\nSmart, engaged co-workers\\nSpeak English in the office with people from over 70 nationalities\\nVirtual stock options - be part of our success story\\nAnnual external training budget - be constantly learning\\nQuarterly Hackathons and weekly tech talks\\nGetYourGuide gift cards\\nRelocation Assistance (varies by role/level)\\nCurious?\\nPlease send in your CV and Cover Letter in English through the form below. We're committed to equal employment opportunity regardless of gender identity, ethnicity, race, sexual orientation, disability status, parental or marital status, or religion.\\nWe'd love to hear from you by emailing jobs@getyourguide.com and make sure you check out life at GetYourGuide on our blog.\\nVor mehr als 30 Tagen\\n- Weiter zur Bewerbung\\nDiesen Job melden\")         \n",
      "-------------END------------\n",
      " \n",
      "('Senior Research Engineer in Automated Reasoning (m/f/d)', 'Taxfix', \"Our story:\\nEvery year millions of people are either filing their taxes in fear or giving up on their tax refund altogether. We're working on fixing that. Our intuitive app enables anyone, regardless of education or background, to file their taxes with newfound confidence.\\n\\nSpread across Berlin and Madrid, Team Taxfix is a compassionate group of solution-finders. We speak our minds openly, and with 250+ professionals from 40 different nationalities, we're rich in ideas and voices. In four years, we've raised over 100 million euros in funding and helped people reclaim more than 400 million euros.\\n\\nYour challenge:\\nAs a Senior Research Engineer, you will be part of a talented multidisciplinary product team. Working with the latest technologies, you will take ownership of the development and optimisation of reasoning algorithms for our tax expert system. Through in-depth research, you'll lead the implementation of new algorithms and optimisations. This is a hands-on role where we will fully support your education in a new programming language—Elixir, with team training and mentoring. You'll also have access to a generous learning and development budget so that you can learn in the style that suits you best.\\n\\nYour responsibilities:\\nDefine the best algorithms and data structures to use in our knowledge base implementation.\\nDefine how to evaluate system correctness.\\nPrioritize algorithmic optimization initiatives that improve performance.\\nDevelop an understanding of our forward-chaining algorithms implemented in our in-house knowledge base.\\nIdentify inefficiency in our algorithms and propose new approaches to improve performance, leading implementations of new algorithms and optimizations.\\nDevelop methodologies for the evaluation of correctness of algorithms, and contribute to the design on performance tests.\\nLearn the Elixir programming language and the stack used for the implementation of our Tax expert system.\\nYour profile:\\nM.Sc / PhD in computer science or related field like Mathematics or Physics.\\n5+ years industry or academic experience in the Automated Reasoning domain.\\nIn Depth Knowledge of SAT, Forward Chaining, Backward chaining, RETE as well as Algorithm Development and Optimization.\\nUnderstanding of Knowledge Representation and Expert Systems.\\nA hands on approach with coding teamed with a curiosity to learn new technologies like Elixir.\\nExcitement for collaboration with different specialists in our Product, Engineering and Business teams.\\nWhy Taxfix?\\n\\nA chance to do meaningful, people-centric work with an international team of passionate professionals.\\nHolistic wellbeing with mental health coaching sessions, a discounted membership to Urban Sports Club, and supplemental child care support.\\nEmployee stock options for all employees—because everyone deserves to benefit from the success they help to create.\\nA generous learning budget to support your personal and professional development and guidance from our internal L&D experts.\\nFull trust to take ownership of your work in a flat hierarchy where feedback is encouraged and expected.\\nDedicated relocation and visa support for those that need it.\\nThe freedom to work from home or our modern office—plus healthy drinks and snacks when you do come in\\nPlenty of opportunities to socialise as a team. In addition to internal tech meetups, our international team hosts regular get-togethers—virtually and in person when possible.\\nExcited? So are we. Learn more about Team Taxfix on our blog and get a glimpse of our culture below:\\n\\nAt Taxfix, we don't just accept diversity—we celebrate it. We're proudly committed to equal employment opportunities no matter your gender, race, religion, age, sexual orientation, colour, disability, or place of origin. We cherish each person's individual contribution to our overall identity, purpose, and goals. Join us!\\nvor 2 Tagen\\n- Weiter zur Bewerbung\\nDiesen Job melden\")         \n",
      "-------------END------------\n",
      " \n",
      "('Data Engineer', 'Nubank', \"About Nubank\\nTackling the complex banking system to empower people in one of the most bureaucratic markets in the world seems like a crazy idea, right? But that's why, how, and where Nubank was born. We fight complexity through our transparent and straightforward products and experiences: a no-fee credit card, a rewards program, a lending platform, and a digital savings account. In a nutshell, we are the most innovative tech company in Latin America, and we are obsessed with building financial services and products that make our customers love us fanatically. With over 30 million customers and $820 million raised in investment rounds, we are the fastest growing digital bank in the world, with offices in Brazil, Germany, Mexico, Argentina and Colombia. And it's still only Day One for us!\\nAbout the Berlin team\\nNubank's Berlin office hosts the data infrastructure platform team. We've built a self-service data processing platform from scratch that empowers everyone at our company to build, process, and query datasets that help push forward their work. Our main users include data analysts, data scientists, business analysts, backend, and data engineers. The team is focused on building well thought out and documented user APIs, backed by scalable data ingestion, processing, and serving systems. We make heavy use of the standard Nubank tech suite (Clojure et. al.), but since we are responsible for the data processing pipeline, you'll also find Scala, Spark, Mesos, Aurora, Airflow. You will also be in touch with DynamoDB, Amazon Aurora, and Datomic for databases, Tekton CI/CD, monitoring/logging with Prometheus and Splunk, and asynchronous communication using Kafka.\\n\\nNubank Data Infrastructure Engineers in Berlin might solve the following problems:\\nSemi-automated creation of data pipelines integrating a wide range of sources to drive business functions and products\\nConstantly refine the data platform to enable a broader set of data applications such as streaming systems, and online ML models to exist\\nImprove user-experience and platform predictability through work on monitoring, UX, and system reliability\\nWork with backend microservices in functional programming languages, such as Clojure\\nCreate intuitive visualizations for monitoring live streaming data sets\\nTriage bugs and exceptions reported in production\\nConduct system load/stress tests\\n\\nCandidates\\nWe are looking for senior Data Infrastructure Engineers with a solid track record of creating efficient, scalable, and accessible solutions, preferably in the domain of data infrastructure and tooling. You will have a meaningful chance to shape architecture, process, and culture while working with leading-edge technologies. We believe in cultivating good inter and intra-team chemistry, enthusiasm for building things, and exercising the amazing capacity to learn new things when we stay humble and open-minded. English language skills are essential.\\n\\nYou will fit well if you have experience with:\\nOperating distributed large-scale data processing frameworks (e.g. Spark, Kafka Streams, Flink)\\nDesigning and optimizing data-pipelines\\nRESTful API oriented design and modular service-oriented architecture\\nUnit, functional, integration testing\\n\\nExperience with the following is desirable:\\nInfrastructure as code (e.g. Ansible, Terraform, CloudFormation)\\nJVM experience (e.g. Java, Scala, Clojure)\\nSQL / NoSQL databases (e.g. PostgreSQL, MySQL, Datomic)\\nStreaming and real-time systems\\n\\nWe expect our candidates to:\\nThrive in dynamic, fast-paced, results-oriented teams\\nBe hungry and enjoy being constantly challenged to learn and do more\\nEmbrace conflict of ideas and like to question the status quo\\nLearn fast and easily adapt to changing situations and priorities\\nBelieve in building great products and doing great work\\nUnderstand the big picture, to be held accountable and make a meaningful contribution with your work\\n\\nBenefits\\n28 days of vacation\\nA competitive compensation package, including the opportunity to earn equity in Nubank\\nWellness and learning allowance\\nFlexible hours\\nRelocation assistance (when outside of Berlin)\\n\\nDiversity and Inclusion at Nubank\\nWe want to have a product for everyone, and we build strong and diverse teams that rise to the challenge. We are a team of the most creative people in technology, and we hire under equal opportunity, irrespective of gender, ethnicity, religion, sexual orientation, or background. We are proud to say that 30% of Nubanker recognize themselves as part of the LGBTQ+ community, and 40% of our team comprises women in all positions and seniority levels. We are a very process-light organization that values human interactions, and that is an essential part of our culture. At Nubank, everyone has the opportunity to speak up and participate, grow, and share ideas.\\nVor mehr als 30 Tagen\\n- Weiter zur Bewerbung\\nDiesen Job melden\")         \n",
      "-------------END------------\n",
      " \n",
      "('Machine Learning Engineer (f/m/x)', 'AUTO1', \"Our Tech department is the driving force behind one of the most successful start-ups in Europe in the last 7 years. Based in Berlin, we have an innovative and driven team that is using cutting-edge technologies to redefine the used car market.\\nYou will be part of a committed and enthusiastic team of Data Scientists, working with machine learning modeling and dealing with challenging problems. As a Machine Learning Engineer (job titled Data Scientist) at AUTO1 Group, you have the opportunity to design, build, and productionize ML models to solve business challenges in advanced topics (pricing, recommendation systems, etc). Together with data scientists, business analysts and production teams, you will help to revolutionize the process and user experience of how people sell and buy cars online and make a real impact on the market.\\nYour role\\nMonitor, optimize and maintain ML solutions\\nPartner with engineering and product teams to architect ML solutions\\nPrepare and process large amounts of data\\nGuide junior engineers and data scientists and promote best practices in engineering\\nWork in close collaboration with data scientists to frame business needs as ML models\\nYour skills\\nProven practical experience as a Machine Learning Engineer or similar role\\nExperience in deploying, maintaining and updating ML models in production. Knowledge of the OOP and the best practices in engineering\\nHands-on experience with a broad range of machine learning techniques and the ability to identify the appropriate technique in different scenarios\\nExperience in effective collaboration, you are a natural team player and communicate fluently in English\\nProficient in SQL, Python and specialized ML libraries (PyTorch, Sklearn, LightGBM, etc). Experience in AWS MLOps is a plus.\\nOur offer\\nColleagues who strive for excellence while using the latest technologies. See what we do in our Tech-Blog: https://auto1.tech\\nRelocation support to Germany which includes visa assistance, apartment search and help with costs\\nEducational budget for your personal growth\\nTeam and company events like Hackathons, International Nights, Company Party, Football and more\\nJoin more than 70 different nationalities in a truly international and diverse working environment\\nApply by uploading your CV with a note of your salary expectations.\\nContact: Kasia Karwacka\\nAUTO1 Group is Europe's leading digital automotive platform. As a dynamic tech company, we are revolutionizing the used car market with our brands wirkaufendeinauto.de, AUTO1.com and Autohero. Our strong team of 4.200 people is dedicated to making Europe-wide car trading and transport as fast, easy, and stress-free as possible for our customers. Grow personally and shape the future of car trading with us.\\nAt AUTO1 Group we live an open culture, believe in direct communication, and value diversity. We welcome every applicant; regardless of gender, ethnic origin, religion, age, sexual identity, disability, or any other non-merit factor.\\nAUTO1 Group\\nVor mehr als 30 Tagen\\n- Weiter zur Bewerbung\\nDiesen Job melden\")         \n",
      "-------------END------------\n",
      " \n",
      "('', 'Zalando Payments GmbH', 'Principal Engineer - Risk Management\\nZalando Payments\\nAs a Principal Engineer Risk Management, you will drive the design of scalable and resilient systems together with our software engineering and product management teams to help deliver on our strategy to offer the best in class machine-learning based risk management and fraud detection solutions.\\nWHERE YOUR EXPERTISE IS NEEDED\\nLead the design of the software architecture for risk management in Payments, write and maintain documentation and a technical roadmap accordingly that fit our strategy\\nDesign of scalable and resilient systems based on the newest technologies, user requirements and needs of the business and define best practises and patterns together with the engineering teams\\nQuantify and report technical debt and influence the product roadmap to reduce it\\nEngage with software engineering, applied science, product management and business stakeholders and define non-functional requirements for the risk management systems\\nWHAT WE’RE LOOKING FOR\\n8+ years of experience in software engineering in payments (preferably incl. Experience in running and deploying machine learning products) incl. 3+ years of experience in designing and operating highly scalable and resilient systems\\nExpert knowledge in hypermedia driven RESTful API design, distributed microservices based on cloud infrastructures and data management\\nStrong communication skills with the ability to share technical topics with bigger audiences even without technical expertise and influence decision making on all levels\\nA technology leader who can convince with compelling arguments and exciting ideas\\nPERKS AT WORK\\nCulture of trust, empowerment and constructive feedback, open source commitment, meetups, game nights, 70+ internal technical and fun guilds, knowledge sharing through tech talks, internal tech academy and blogs , product demos, parties & events\\nCompetitive salary, employee share shop, 40% Zalando shopping discount, discounts from external partners, centrally located offices, public transport discounts, municipality services, great IT equipment, flexible working times, additional holidays and volunteering time off, free beverages and fruits, diverse sports and health offerings\\nExtensive onboarding, mentoring and personal development opportunities and an international team of experts\\nRelocation assistance for internationals, PME family service and parent & child rooms* (*available only in select locations)\\nWe celebrate diversity and are committed to building teams that represent a variety of backgrounds, perspectives and skills. All employment is decided on the basis of qualifications, merit and business need.\\nZalando Payments builds the technologies for all financial transactions in the Zalando fashion store and our other consumer-facing apps. We work to deliver a flawless user experience in the checkout, as well as the processing of payments and reconciliation in the back-end. Through smart risk steering, we boost conversion and deliver a competitive advantage to our customers, taking in the entire financial process.\\nZalando\\nvor 5 Tagen\\n- Weiter zur Bewerbung\\nDiesen Job melden')         \n",
      "-------------END------------\n",
      " \n",
      "('Data Engineer - Marketing Services', 'Taxfix', \"Our story:\\nEvery year millions of people are either filing their taxes in fear or giving up on their tax refund altogether. We're working on fixing that. Our intuitive app enables anyone, regardless of education or background, to file their taxes with newfound confidence.\\n\\nSpread across Berlin and Madrid, Team Taxfix is a compassionate group of solution-finders. We speak our minds openly, and with 250+ professionals from 40 different nationalities, we're rich in ideas and voices. In four years, we've raised over 100 million euros in funding and helped people reclaim more than 400 million euros.\\n\\nYour challenge:\\nWe are looking for an experienced Data Engineer to build tools to track and optimize Taxfix’s marketing activities. Our team uses a variety of tools and taps into different data sources, both in-house and 3rd party. We build tools that serve our stakeholders company-wide: Performance Marketing, Content Marketing, CRM, and Marketing Analytics. You will work in a cross-functional team with product managers, analysts, full stack engineers and data engineers to bring Taxfix to the next level.\\n\\nYour responsibilities:\\nIterate on “Marketing Services as a product”: continue to establish methodology for tracking marketing activities.\\nManage data flows from ad-networks to our systems and vice-versa.\\nArchitect and develop real-time and batch data streaming pipelines using Airflow and Snowflake.\\nDevelop Data Governance tools: data catalog, events monitoring, GDPR controls.\\nEstablish team-wide standards: excellent documentation, monitoring & alerting, code quality, unit testing, CI + CD\\nYour profile:\\nTwo or more years of working experience as a Data Engineer or in a similar position.\\nExperience working in the domain of mobile apps and events tracking.\\nExperience working with unstructured datasets and events streaming pipelines.\\nMust have: you are used to working with Python & Kubernetes or Docker\\nYou can design and manage cloud-hosted Infrastructure (Google Cloud or AWS).\\nBonus Skills: Airflow, Snowflake SQL, Segment, Lambda Functions\\nFluent in English.\\nWhy Taxfix?\\n\\nA chance to do meaningful, people-centric work with an international team of passionate professionals.\\nHolistic wellbeing with mental health coaching sessions, a discounted membership to Urban Sports Club, and supplemental child care support.\\nEmployee stock options for all employees—because everyone deserves to benefit from the success they help to create.\\nDedicated relocation and visa support for those that need it.\\nThe freedom to work from home or our modern office—plus healthy drinks and snacks when you do come in.\\n27 annual vacation days and flexible working hours.\\nFull trust to take ownership of your work in a flat hierarchy where feedback is encouraged and expected.\\nA generous learning budget to support your personal and professional development and guidance from our internal L&D experts\\nChoose the internal tech community that excites you the most and spend 20% of your time collaborating and learning from your fellow domain experts.\\nPlenty of opportunities to socialise as a team. In addition to internal tech meetups, our international team hosts regular get-togethers—virtually and in person when possible.\\nFree tax declaration filing, of course, through the Taxfix app—and internal support for all personal tax-related questions.\\nHave a four-legged friend in your life? We’re happy to have dogs join us in the office.\\nExcited? So are we. Learn more about Team Taxfix on our blog and get a glimpse of our culture below:\\n\\nAt Taxfix, we don't just accept diversity—we celebrate it. We're proudly committed to equal employment opportunities no matter your gender, race, religion, age, sexual orientation, colour, disability, or place of origin. We cherish each person's individual contribution to our overall identity, purpose, and goals. Join us!\\nvor 25 Tagen\\n- Weiter zur Bewerbung\\nDiesen Job melden\")         \n",
      "-------------END------------\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print_top_jobs(400, 10) # duplicates 3050; 2020; 400\n",
    "#print_top_jobs(5000) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-soviet",
   "metadata": {},
   "source": [
    "## Improve the model\n",
    "\n",
    "- try bigrams instead ot unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-preliminary",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_small = df_eng['clean'][:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Phrases(texts_small, min_count=1, threshold=2, delimiter=b' ')\n",
    "\n",
    "bigram_phraser = Phraser(bigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-drinking",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "bigram_token = []\n",
    "for sent in texts_small:\n",
    "    bigram_token.append(bigram_phraser[sent])\n",
    "    \n",
    "bigram_token[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-challenge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
