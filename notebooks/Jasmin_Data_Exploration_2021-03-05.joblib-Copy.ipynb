{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "medium-exhibition",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "outer-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import altair as alt\n",
    "from gensim.models import Word2Vec\n",
    "from fydjob.NLPFrame import NLPFrame\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "laden-council",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = joblib.load('/Users/jasminkazi/code/mizzle-toe/find-your-dream-job/fydjob/output/indeed_proc/processed_data.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exclusive-research",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jasminkazi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jasminkazi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jasminkazi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from /Users/jasminkazi/code/mizzle-toe/find-your-dream-job/fydjob/output/nlp_frame.joblib\n"
     ]
    }
   ],
   "source": [
    "data = NLPFrame().df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "elegant-extra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ok': True}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://0.0.0.0:3000'\n",
    "response = requests.get(url)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-lyric",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-cargo",
   "metadata": {},
   "source": [
    "### Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "greenhouse-imperial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5881, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "disturbed-kingdom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_text</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>job_info</th>\n",
       "      <th>job_link</th>\n",
       "      <th>query_text</th>\n",
       "      <th>source</th>\n",
       "      <th>tag_language</th>\n",
       "      <th>reviews</th>\n",
       "      <th>job_info_tokenized</th>\n",
       "      <th>job_text_tokenized</th>\n",
       "      <th>job_text_tokenized_titlecase</th>\n",
       "      <th>job_title_tokenized</th>\n",
       "      <th>job_text_tokenized_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist / Matching Engineer (m/w/d)</td>\n",
       "      <td>You are responsible for improvement of Taledo’...</td>\n",
       "      <td>Taledo</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Scientist / Matching Engineer (m/w/d)\\nTa...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>scrape_json</td>\n",
       "      <td>en</td>\n",
       "      <td>NULL</td>\n",
       "      <td>[data, scientist, matching, engineer, mwd, tal...</td>\n",
       "      <td>[you, are, responsible, for, improvement, of, ...</td>\n",
       "      <td>[Data, Scientist, Matching, Engineer, mwd, Tal...</td>\n",
       "      <td>[data, scientist, matching, engineer, mwd]</td>\n",
       "      <td>[responsible, improvement, taledos, search, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Senior Software Engineer - Data Platform</td>\n",
       "      <td>We are looking for a Senior Software Engineer ...</td>\n",
       "      <td>Zalando SE</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Senior Software Engineer - Data Platform\\nZala...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>scrape_json</td>\n",
       "      <td>en</td>\n",
       "      <td>NULL</td>\n",
       "      <td>[senior, software, engineer, data, platform, z...</td>\n",
       "      <td>[we, are, looking, for, a, senior, software, e...</td>\n",
       "      <td>[Senior, Software, Engineer, Data, Platform, Z...</td>\n",
       "      <td>[senior, software, engineer, data, platform]</td>\n",
       "      <td>[looking, senior, software, engineer, extensiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Senior Data Engineer (m/w/t)</td>\n",
       "      <td>As a member of the Data Engineering Team, you ...</td>\n",
       "      <td>Quandoo GmbH</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Senior Data Engineer (m/w/t)\\nQuandoo GmbH17 B...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>scrape_json</td>\n",
       "      <td>en</td>\n",
       "      <td>NULL</td>\n",
       "      <td>[senior, data, engineer, mwt, quandoo, gmbh, b...</td>\n",
       "      <td>[as, a, member, of, the, data, engineering, te...</td>\n",
       "      <td>[Senior, Data, Engineer, mwt, Quandoo, GmbH, B...</td>\n",
       "      <td>[senior, data, engineer, mwt]</td>\n",
       "      <td>[member, data, engineering, team, responsible,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Data Engineer (w/m/d)</td>\n",
       "      <td>We are digitty.io – an international start-up ...</td>\n",
       "      <td>digitty.io</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Engineer (w/m/d)\\ndigitty.io - Berlin</td>\n",
       "      <td>NULL</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>scrape_json</td>\n",
       "      <td>en</td>\n",
       "      <td>NULL</td>\n",
       "      <td>[data, engineer, wmd, digittyio, berlin]</td>\n",
       "      <td>[we, are, digittyio, an, international, startu...</td>\n",
       "      <td>[Data, Engineer, wmd, digittyio, Berlin]</td>\n",
       "      <td>[data, engineer, wmd]</td>\n",
       "      <td>[digittyio, international, startup, headquarte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>We activate data for our clients by using stat...</td>\n",
       "      <td>Gemma Analytics</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Engineer\\nGemma Analytics - Berlin</td>\n",
       "      <td>NULL</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>scrape_json</td>\n",
       "      <td>en</td>\n",
       "      <td>NULL</td>\n",
       "      <td>[data, engineer, gemma, analytics, berlin]</td>\n",
       "      <td>[we, activate, data, for, our, clients, by, us...</td>\n",
       "      <td>[Data, Engineer, Gemma, Analytics, Berlin]</td>\n",
       "      <td>[data, engineer]</td>\n",
       "      <td>[activate, data, client, using, stateoftheart,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id                                   job_title  \\\n",
       "0       1  Data Scientist / Matching Engineer (m/w/d)   \n",
       "1       2    Senior Software Engineer - Data Platform   \n",
       "2       3                Senior Data Engineer (m/w/t)   \n",
       "3       4                       Data Engineer (w/m/d)   \n",
       "4       5                               Data Engineer   \n",
       "\n",
       "                                            job_text          company  \\\n",
       "0  You are responsible for improvement of Taledo’...           Taledo   \n",
       "1  We are looking for a Senior Software Engineer ...       Zalando SE   \n",
       "2  As a member of the Data Engineering Team, you ...     Quandoo GmbH   \n",
       "3  We are digitty.io – an international start-up ...       digitty.io   \n",
       "4  We activate data for our clients by using stat...  Gemma Analytics   \n",
       "\n",
       "  location                                           job_info job_link  \\\n",
       "0   Berlin  Data Scientist / Matching Engineer (m/w/d)\\nTa...     NULL   \n",
       "1   Berlin  Senior Software Engineer - Data Platform\\nZala...     NULL   \n",
       "2   Berlin  Senior Data Engineer (m/w/t)\\nQuandoo GmbH17 B...     NULL   \n",
       "3   Berlin         Data Engineer (w/m/d)\\ndigitty.io - Berlin     NULL   \n",
       "4   Berlin            Data Engineer\\nGemma Analytics - Berlin     NULL   \n",
       "\n",
       "      query_text       source tag_language reviews  \\\n",
       "0  data engineer  scrape_json           en    NULL   \n",
       "1  data engineer  scrape_json           en    NULL   \n",
       "2  data engineer  scrape_json           en    NULL   \n",
       "3  data engineer  scrape_json           en    NULL   \n",
       "4  data engineer  scrape_json           en    NULL   \n",
       "\n",
       "                                  job_info_tokenized  \\\n",
       "0  [data, scientist, matching, engineer, mwd, tal...   \n",
       "1  [senior, software, engineer, data, platform, z...   \n",
       "2  [senior, data, engineer, mwt, quandoo, gmbh, b...   \n",
       "3           [data, engineer, wmd, digittyio, berlin]   \n",
       "4         [data, engineer, gemma, analytics, berlin]   \n",
       "\n",
       "                                  job_text_tokenized  \\\n",
       "0  [you, are, responsible, for, improvement, of, ...   \n",
       "1  [we, are, looking, for, a, senior, software, e...   \n",
       "2  [as, a, member, of, the, data, engineering, te...   \n",
       "3  [we, are, digittyio, an, international, startu...   \n",
       "4  [we, activate, data, for, our, clients, by, us...   \n",
       "\n",
       "                        job_text_tokenized_titlecase  \\\n",
       "0  [Data, Scientist, Matching, Engineer, mwd, Tal...   \n",
       "1  [Senior, Software, Engineer, Data, Platform, Z...   \n",
       "2  [Senior, Data, Engineer, mwt, Quandoo, GmbH, B...   \n",
       "3           [Data, Engineer, wmd, digittyio, Berlin]   \n",
       "4         [Data, Engineer, Gemma, Analytics, Berlin]   \n",
       "\n",
       "                            job_title_tokenized  \\\n",
       "0    [data, scientist, matching, engineer, mwd]   \n",
       "1  [senior, software, engineer, data, platform]   \n",
       "2                 [senior, data, engineer, mwt]   \n",
       "3                         [data, engineer, wmd]   \n",
       "4                              [data, engineer]   \n",
       "\n",
       "                        job_text_tokenized_processed  \n",
       "0  [responsible, improvement, taledos, search, ma...  \n",
       "1  [looking, senior, software, engineer, extensiv...  \n",
       "2  [member, data, engineering, team, responsible,...  \n",
       "3  [digittyio, international, startup, headquarte...  \n",
       "4  [activate, data, client, using, stateoftheart,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "behavioral-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['job_info_tokenized','job_text_tokenized_titlecase', 'job_title_tokenized','job_text_tokenized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "muslim-slovak",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company',\n",
       " 'job_id',\n",
       " 'job_info',\n",
       " 'job_link',\n",
       " 'job_text',\n",
       " 'job_text_tokenized_processed',\n",
       " 'job_title',\n",
       " 'location',\n",
       " 'query_text',\n",
       " 'reviews',\n",
       " 'source',\n",
       " 'tag_language'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "external-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(df.columns)-(set(data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-coordinator",
   "metadata": {},
   "source": [
    "### No. of...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "coordinate-massachusetts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5881"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['job_title'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bridal-chair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['data engineer', 'business intelligence', 'data scientist',\n",
       "       'data science', 'NULL'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['query_text'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "auburn-procedure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min:  10.0  max:  NULL\n"
     ]
    }
   ],
   "source": [
    "print('min: ',data['reviews'].min(), ' max: ', data['reviews'].max())\n",
    "#data['reviews'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "obvious-kazakhstan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.groupby.generic.DataFrameGroupBy"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying out modifying the df so I don't have a df per chart\n",
    "source_lang = data['tag_language'].value_counts()\n",
    "type(source_lang)\n",
    "source_lang= data.groupby('tag_language')\n",
    "type(source_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "reported-blocking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lanugauges\n",
    "data['tag_language'].nunique()\n",
    "source_lang = pd.DataFrame(data['tag_language'].value_counts()).reset_index()\n",
    "source_lang = source_lang.rename(columns = {'index':'Posting Language', 'tag_language':'Count'})\n",
    "type(source_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "distinguished-neutral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-025b6a7b9a4f44d9bcada1f952477d1f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-025b6a7b9a4f44d9bcada1f952477d1f\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-025b6a7b9a4f44d9bcada1f952477d1f\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-ad8511f7421f8f3ec90a4639c9ec54c5\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"type\": \"quantitative\", \"field\": \"Count\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"Count\", \"stack\": \"normalize\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-ad8511f7421f8f3ec90a4639c9ec54c5\": [{\"Posting Language\": \"en\", \"Count\": 5881}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(source_lang).mark_bar().encode(\n",
    "    x=alt.X('Count', stack ='normalize'),\n",
    "    #y='Posting Language',\n",
    "    color = 'Count'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "weird-commitment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-44ff88f9d14e450ea7eaadb6a4482621\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-44ff88f9d14e450ea7eaadb6a4482621\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-44ff88f9d14e450ea7eaadb6a4482621\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-ad8511f7421f8f3ec90a4639c9ec54c5\"}, \"mark\": \"bar\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"axis\": {\"format\": \".0%\"}, \"field\": \"Percentage\"}, \"y\": {\"type\": \"nominal\", \"field\": \"Posting Language\"}}, \"transform\": [{\"joinaggregate\": [{\"op\": \"sum\", \"field\": \"Count\", \"as\": \"Total\"}]}, {\"calculate\": \"datum.Count / datum.Total\", \"as\": \"Percentage\"}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-ad8511f7421f8f3ec90a4639c9ec54c5\": [{\"Posting Language\": \"en\", \"Count\": 5881}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(source_lang).transform_joinaggregate(\n",
    "    Total='sum(Count)',\n",
    ").transform_calculate(\n",
    "    Percentage=\"datum.Count / datum.Total\"\n",
    ").mark_bar().encode(\n",
    "    alt.X('Percentage:Q', axis=alt.Axis(format='.0%')),\n",
    "    y='Posting Language:N'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "alternate-disclosure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiring Companies:  2496\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Broad Institute</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>McKinsey &amp; Company</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>CytomX Therapeutics, Inc.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>ACADIA Pharmaceuticals Inc.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>Neilson Financial Services</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>Systems Planning and Analysis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>Change Healthcare</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2496 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Company  Count\n",
       "0                        Amazon.com    277\n",
       "1                         Microsoft    120\n",
       "2                            Google     57\n",
       "3                   Broad Institute     44\n",
       "4                McKinsey & Company     40\n",
       "...                             ...    ...\n",
       "2491      CytomX Therapeutics, Inc.      1\n",
       "2492    ACADIA Pharmaceuticals Inc.      1\n",
       "2493     Neilson Financial Services      1\n",
       "2494  Systems Planning and Analysis      1\n",
       "2495              Change Healthcare      1\n",
       "\n",
       "[2496 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Companies\n",
    "print('Hiring Companies: ', data['company'].nunique())\n",
    "source_comp = pd.DataFrame(data['company'].value_counts().reset_index())\n",
    "source_comp= source_comp.rename(columns = {'index':'Company', 'company':'Count'})\n",
    "source_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "approximate-disposal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-4bdeea118ed7462eaef8d5eae4d10e56\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-4bdeea118ed7462eaef8d5eae4d10e56\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-4bdeea118ed7462eaef8d5eae4d10e56\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": \"bar\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"Count\"}, \"y\": {\"type\": \"nominal\", \"field\": \"Company\", \"sort\": \"-x\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"left\", \"baseline\": \"middle\", \"dx\": 3}, \"encoding\": {\"text\": {\"type\": \"quantitative\", \"field\": \"Count\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"Count\"}, \"y\": {\"type\": \"nominal\", \"field\": \"Company\", \"sort\": \"-x\"}}}], \"data\": {\"name\": \"data-a775641875480f32d806b06723efc0c6\"}, \"height\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-a775641875480f32d806b06723efc0c6\": [{\"Company\": \"Amazon.com\", \"Count\": 277}, {\"Company\": \"Microsoft\", \"Count\": 120}, {\"Company\": \"Google\", \"Count\": 57}, {\"Company\": \"Broad Institute\", \"Count\": 44}, {\"Company\": \"McKinsey & Company\", \"Count\": 40}, {\"Company\": \"Harnham\", \"Count\": 38}, {\"Company\": \"Walmart eCommerce\", \"Count\": 37}, {\"Company\": \"Zalando\", \"Count\": 36}, {\"Company\": \"Delivery Hero\", \"Count\": 31}, {\"Company\": \"Brigham & Women's Hospital(BWH)\", \"Count\": 29}, {\"Company\": \"Biogen\", \"Count\": 28}, {\"Company\": \"Amazon Development Center DEU\", \"Count\": 28}, {\"Company\": \"Illumina\", \"Count\": 27}, {\"Company\": \"Amgen\", \"Count\": 27}, {\"Company\": \"JD.com\", \"Count\": 25}, {\"Company\": \"Sanofi\", \"Count\": 24}, {\"Company\": \"Zalando SE\", \"Count\": 24}, {\"Company\": \"Lab126\", \"Count\": 23}, {\"Company\": \"Wayfair\", \"Count\": 23}, {\"Company\": \"University of Texas at Austin\", \"Count\": 23}, {\"Company\": \"Zillow Group\", \"Count\": 23}, {\"Company\": \"Cedars-Sinai\", \"Count\": 23}, {\"Company\": \"Oath Inc\", \"Count\": 22}, {\"Company\": \"Massachusetts General Hospital(MGH)\", \"Count\": 22}, {\"Company\": \"University of Washington\", \"Count\": 21}, {\"Company\": \"Harvard University\", \"Count\": 21}, {\"Company\": \"Genentech\", \"Count\": 21}, {\"Company\": \"Nielsen\", \"Count\": 20}, {\"Company\": \"Autodesk\", \"Count\": 20}, {\"Company\": \"Quora\", \"Count\": 19}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_comp = source_comp.nlargest(30, 'Count')\n",
    "\n",
    "bars = alt.Chart(source_comp).mark_bar().encode(\n",
    "    x='Count:Q',\n",
    "    y=alt.Y('Company:N', sort='-x')\n",
    ")\n",
    "\n",
    "text = bars.mark_text(\n",
    "    align='left',\n",
    "    baseline='middle',\n",
    "    dx=3  # Nudges text to right so it doesn't appear on top of the bar\n",
    ").encode(\n",
    "    text='Count:Q'\n",
    ")\n",
    "\n",
    "(bars + text).properties(height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "radical-bradford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of query_text:  5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NULL</td>\n",
       "      <td>5262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data science</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data engineer</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data scientist</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business intelligence</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Job  Count\n",
       "0                   NULL   5262\n",
       "1           data science    178\n",
       "2          data engineer    172\n",
       "3         data scientist    161\n",
       "4  business intelligence    108"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query_text\n",
    "print('No of query_text: ',data['query_text'].nunique())\n",
    "source_job = pd.DataFrame(data['query_text'].value_counts().reset_index())\n",
    "source_job= source_job.rename(columns = {'index':'Job', 'query_text':'Count'})\n",
    "source_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "junior-pavilion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-1217be32c0dc4f1db274b263084a3c4c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-1217be32c0dc4f1db274b263084a3c4c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-1217be32c0dc4f1db274b263084a3c4c\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-3678e1f37ed71d8ad1c6ab4bbf97f953\"}, \"mark\": \"bar\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"Count\"}, \"y\": {\"type\": \"nominal\", \"field\": \"Job\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-3678e1f37ed71d8ad1c6ab4bbf97f953\": [{\"Job\": \"NULL\", \"Count\": 5262}, {\"Job\": \"data science\", \"Count\": 178}, {\"Job\": \"data engineer\", \"Count\": 172}, {\"Job\": \"data scientist\", \"Count\": 161}, {\"Job\": \"business intelligence\", \"Count\": 108}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(source_job).mark_bar().encode(\n",
    "    x='Count',\n",
    "    y='Job'\n",
    ")\n",
    "#rule = alt.Chart(source_job).mark_rule(color='red').encode(\n",
    "#    x='mean(Count):Q'\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dressed-awareness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['job_text_tokenized_processed'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "korean-toddler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business': ['analyst',\n",
       "  'report',\n",
       "  'strategy',\n",
       "  'consult',\n",
       "  'distribution',\n",
       "  'accounting',\n",
       "  'entrepreneurship',\n",
       "  'reporting',\n",
       "  'stakeholder',\n",
       "  'measurable',\n",
       "  'analyze',\n",
       "  'managing',\n",
       "  'management',\n",
       "  'administrative',\n",
       "  'hr',\n",
       "  'feasibility',\n",
       "  'solution',\n",
       "  'analysis',\n",
       "  'logistic',\n",
       "  'visualisation',\n",
       "  'sales',\n",
       "  'advertising',\n",
       "  'entrepreneurial',\n",
       "  'profitable',\n",
       "  'analyse',\n",
       "  'efficiency',\n",
       "  'entrepreneur',\n",
       "  'strategic',\n",
       "  'analytical',\n",
       "  'commercial',\n",
       "  'olap',\n",
       "  'consulting',\n",
       "  'crm',\n",
       "  'industry',\n",
       "  'client',\n",
       "  'kpi',\n",
       "  'visualization',\n",
       "  'planning',\n",
       "  'strategical',\n",
       "  'analytics',\n",
       "  'analytic',\n",
       "  'administration',\n",
       "  'dashboards',\n",
       "  'business',\n",
       "  'marketing',\n",
       "  'bd',\n",
       "  'scm'],\n",
       " 'knowledge': ['statistics',\n",
       "  'pipeline',\n",
       "  'etl',\n",
       "  'reinforcement',\n",
       "  'geospatial',\n",
       "  'recurrent',\n",
       "  'tuning',\n",
       "  'algorithmical',\n",
       "  'bayes',\n",
       "  'methodical',\n",
       "  'cnn',\n",
       "  'outlier',\n",
       "  'signal',\n",
       "  'pca',\n",
       "  'databases',\n",
       "  'graph',\n",
       "  'knn',\n",
       "  'predictable',\n",
       "  'cluster',\n",
       "  'convolutional',\n",
       "  'unsupervised',\n",
       "  'research',\n",
       "  'gis',\n",
       "  'svm',\n",
       "  'optimizing',\n",
       "  'bioinformatics',\n",
       "  'queries',\n",
       "  'pipelines',\n",
       "  'logistic',\n",
       "  'chatbot',\n",
       "  'metric',\n",
       "  'classification',\n",
       "  'nlp',\n",
       "  'nn',\n",
       "  'segmentation',\n",
       "  'usercentric',\n",
       "  'supervised',\n",
       "  'saas',\n",
       "  'regression',\n",
       "  'diagnostic',\n",
       "  'modeling',\n",
       "  'cleansing',\n",
       "  'query',\n",
       "  'prediction',\n",
       "  'statistic',\n",
       "  'mobility',\n",
       "  'frontend',\n",
       "  'nvidias',\n",
       "  'variable',\n",
       "  'cleaning',\n",
       "  'stochastic',\n",
       "  'methodological',\n",
       "  'bioinformatic',\n",
       "  'rnn',\n",
       "  'cicd',\n",
       "  'biostatistics',\n",
       "  'dashboard',\n",
       "  'scientific',\n",
       "  'normalization',\n",
       "  'native',\n",
       "  'logistics',\n",
       "  'causal',\n",
       "  'causality',\n",
       "  'optimization',\n",
       "  'warehousing',\n",
       "  'sequencing',\n",
       "  'kpi',\n",
       "  'recommender',\n",
       "  'security',\n",
       "  'blockchain',\n",
       "  'visualization',\n",
       "  'boosting',\n",
       "  'econometrics',\n",
       "  'uxui',\n",
       "  'clustering',\n",
       "  'bayesian',\n",
       "  'hardware',\n",
       "  'userfirst',\n",
       "  'holistic',\n",
       "  'backend',\n",
       "  'science',\n",
       "  'correlation',\n",
       "  'hyperparameter',\n",
       "  'salesforcecom',\n",
       "  'dbaas',\n",
       "  'physics',\n",
       "  'econometric',\n",
       "  'algorithmic',\n",
       "  'predictive',\n",
       "  'forecasting',\n",
       "  'ai',\n",
       "  'algorithms',\n",
       "  'ocr',\n",
       "  'scrum',\n",
       "  'mathematics',\n",
       "  'recommendations',\n",
       "  'scalable',\n",
       "  'agile',\n",
       "  'probability',\n",
       "  'database',\n",
       "  'devops',\n",
       "  'api',\n",
       "  'gbm',\n",
       "  'opensource',\n",
       "  'lstm',\n",
       "  'svd',\n",
       "  'hypothesis',\n",
       "  'artificial',\n",
       "  'chi',\n",
       "  'quantitative'],\n",
       " 'programming': ['keras',\n",
       "  'powerpoint',\n",
       "  'angular',\n",
       "  'excel',\n",
       "  'kafka',\n",
       "  'mongodb',\n",
       "  'microsoft',\n",
       "  'julia',\n",
       "  'mysql',\n",
       "  'nodejs',\n",
       "  'tensorflow',\n",
       "  'scikit',\n",
       "  'pytorch',\n",
       "  'cntk',\n",
       "  'broom',\n",
       "  'matplotlib',\n",
       "  'architect',\n",
       "  'mllib',\n",
       "  's3',\n",
       "  'caret',\n",
       "  'lambda',\n",
       "  'c++',\n",
       "  'glmnet',\n",
       "  'gcp',\n",
       "  'ldap',\n",
       "  'spark',\n",
       "  'spacy',\n",
       "  'java',\n",
       "  'dt',\n",
       "  'relational',\n",
       "  'mlr',\n",
       "  'integrate',\n",
       "  'shiny',\n",
       "  'slack',\n",
       "  'prophet',\n",
       "  'incident',\n",
       "  'bestpractice',\n",
       "  'seaborn',\n",
       "  'numpy',\n",
       "  'rbokeh',\n",
       "  'spice',\n",
       "  'multicloud',\n",
       "  'django',\n",
       "  'bigtable',\n",
       "  'looker',\n",
       "  'plsql',\n",
       "  'unixlinux',\n",
       "  'pig',\n",
       "  'birt',\n",
       "  'linux',\n",
       "  'gerrit',\n",
       "  'dataflow',\n",
       "  'aws',\n",
       "  'node',\n",
       "  'scala',\n",
       "  'github',\n",
       "  'rpython',\n",
       "  'caffe',\n",
       "  'mysqlmariadb',\n",
       "  'kotlin',\n",
       "  'disrupt',\n",
       "  'alexa',\n",
       "  'rcharts',\n",
       "  'python',\n",
       "  'clojure',\n",
       "  'techcrunch',\n",
       "  'eltbased',\n",
       "  'jquery',\n",
       "  'iqvias',\n",
       "  'disruptive',\n",
       "  'rust',\n",
       "  'azure',\n",
       "  'bioconductor',\n",
       "  'powerapps',\n",
       "  'ggvis',\n",
       "  'lightgbm',\n",
       "  'postgresql',\n",
       "  'architecture',\n",
       "  'tensor',\n",
       "  'google',\n",
       "  'integration',\n",
       "  'ec2',\n",
       "  'nginx',\n",
       "  'oracle',\n",
       "  'pyspark',\n",
       "  'rvest',\n",
       "  'sql',\n",
       "  'heroku',\n",
       "  'datasciencer',\n",
       "  'hbase',\n",
       "  'cloud',\n",
       "  'algolia',\n",
       "  'h20',\n",
       "  'text2vec',\n",
       "  'kubernetes',\n",
       "  'mssql',\n",
       "  'einstein',\n",
       "  'nltk',\n",
       "  'sas',\n",
       "  'snowballc',\n",
       "  'rmarkdown',\n",
       "  'cognos',\n",
       "  'redshift',\n",
       "  'datadriven',\n",
       "  'd3',\n",
       "  'mapreduce',\n",
       "  'rstudio',\n",
       "  'hana',\n",
       "  'javascript',\n",
       "  'technician',\n",
       "  'net',\n",
       "  'perl',\n",
       "  'plotly',\n",
       "  'airflow',\n",
       "  'flask',\n",
       "  'maintainable',\n",
       "  'mesh',\n",
       "  'react',\n",
       "  'xgboost',\n",
       "  'scipy',\n",
       "  'rapidminer',\n",
       "  'knitr',\n",
       "  'transformational',\n",
       "  'r',\n",
       "  'terraform',\n",
       "  'scikitlearn',\n",
       "  'firebase',\n",
       "  'matlab',\n",
       "  'mahout',\n",
       "  'golive',\n",
       "  'theano',\n",
       "  'tableau',\n",
       "  'elasticsearch',\n",
       "  'postgres',\n",
       "  'quantmod',\n",
       "  'dask',\n",
       "  'salesforce',\n",
       "  'sagemaker',\n",
       "  'quanteda',\n",
       "  'git',\n",
       "  'iqvia',\n",
       "  'apache',\n",
       "  'powerbi',\n",
       "  'ssrs',\n",
       "  'splunk',\n",
       "  'pandas',\n",
       "  'dplyr',\n",
       "  'slidify',\n",
       "  'jupyter',\n",
       "  'hadoop',\n",
       "  'c',\n",
       "  'leaflet',\n",
       "  'snowflake',\n",
       "  'bokeh',\n",
       "  'tf',\n",
       "  'php',\n",
       "  'qlik',\n",
       "  'esquisse',\n",
       "  'lubridate',\n",
       "  'postgressql',\n",
       "  'rsqlite',\n",
       "  'swirl',\n",
       "  'ggplot2',\n",
       "  'sklearn',\n",
       "  'nosql',\n",
       "  'magrittr',\n",
       "  'streamline',\n",
       "  'pentaho',\n",
       "  'unix',\n",
       "  'cassandra',\n",
       "  'mxnet',\n",
       "  'solr',\n",
       "  'hive',\n",
       "  'dash',\n",
       "  'stringr',\n",
       "  'vba',\n",
       "  'rmysql',\n",
       "  'rstan',\n",
       "  'bigquery',\n",
       "  'ruby',\n",
       "  'kubeflow',\n",
       "  'docker',\n",
       "  'h2o',\n",
       "  'interface',\n",
       "  'mlflow',\n",
       "  'rcrawler',\n",
       "  'janitor',\n",
       "  'codevelopment',\n",
       "  'spss'],\n",
       " 'soft_skills': ['project',\n",
       "  'leadership',\n",
       "  'training',\n",
       "  'empathic',\n",
       "  'coordination',\n",
       "  'organizational',\n",
       "  'inventive',\n",
       "  'management',\n",
       "  'mindful',\n",
       "  'professional',\n",
       "  'conflict',\n",
       "  'honesty',\n",
       "  'coaching',\n",
       "  'emotional',\n",
       "  'organize',\n",
       "  'listening',\n",
       "  'proactive',\n",
       "  'dependable',\n",
       "  'responsible',\n",
       "  'determined',\n",
       "  'decisionmaking',\n",
       "  'social',\n",
       "  'empathy',\n",
       "  'creative',\n",
       "  'skilled',\n",
       "  'creativity',\n",
       "  'verbal',\n",
       "  'trustworthy',\n",
       "  'teamwork',\n",
       "  'committed',\n",
       "  'communicative',\n",
       "  'charismatic',\n",
       "  'innovation',\n",
       "  'openness',\n",
       "  'constructive',\n",
       "  'nonverbal',\n",
       "  'flexibility',\n",
       "  'resultdriven',\n",
       "  'honest',\n",
       "  'time',\n",
       "  'loyal',\n",
       "  'capable',\n",
       "  'vision',\n",
       "  'strengths',\n",
       "  'trustful',\n",
       "  'reliability',\n",
       "  'empathetic',\n",
       "  'accountable',\n",
       "  'organization',\n",
       "  'dynamic',\n",
       "  'collaboration',\n",
       "  'tolerant',\n",
       "  'conceptual',\n",
       "  'energetic',\n",
       "  'assertive',\n",
       "  'ownership',\n",
       "  'interpersonal',\n",
       "  'driven',\n",
       "  'strategical',\n",
       "  'openmindedness',\n",
       "  'positive',\n",
       "  'reliable',\n",
       "  'inclusive',\n",
       "  'comittment',\n",
       "  'initiative',\n",
       "  'teamplayer',\n",
       "  'independent',\n",
       "  'selfinitiative',\n",
       "  'authentic',\n",
       "  'motivation',\n",
       "  'responsibility',\n",
       "  'flexible',\n",
       "  'innovative',\n",
       "  'collaborative',\n",
       "  'motivational',\n",
       "  'volunteering',\n",
       "  'communication',\n",
       "  'presentation',\n",
       "  'personality',\n",
       "  'resourceful',\n",
       "  'negotiation',\n",
       "  'integrity',\n",
       "  'intercultural',\n",
       "  'crosscultural']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fydjob import utils\n",
    "utils.load_skills()     #loads the skills from JSON file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "thorough-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the skill sets\n",
    "categories = utils.load_skills()\n",
    "categories.keys()\n",
    "bus_skills = set(utils.load_skills()['business'])\n",
    "knowledge_skills = set(utils.load_skills()['knowledge'])\n",
    "code_skills = set(utils.load_skills()['programming'])\n",
    "soft_skills = set(utils.load_skills()['soft_skills'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "simple-going",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'job_text_tokenized'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/fydjob/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'job_text_tokenized'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2ce13297c7a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mskill_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'job_text_tokenized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcode_skills\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mskill_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/fydjob/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/fydjob/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'job_text_tokenized'"
     ]
    }
   ],
   "source": [
    "#get skill for the first token\n",
    "skill_0 = []\n",
    "\n",
    "for word in data['job_text_tokenized'][0]:\n",
    "    if word in code_skills:\n",
    "        skill_0.append(word)\n",
    "        \n",
    "skill_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the occurences\n",
    "from collections import Counter\n",
    "counter0 = Counter(data['job_text_tokenized'][0])\n",
    "\n",
    "#occs = {x: counter[x] for x in counter.keys() & set(skill_0)}\n",
    "\n",
    "bus_occs = {x: counter0[x] for x in counter0.keys() & set(bus_skills)}\n",
    "code_occs = {x: counter0[x] for x in counter0.keys() & set(code_skills)}\n",
    "knowledge_occs ={x: counter0[x] for x in counter0.keys() & set(knowledge_skills)}\n",
    "soft_occs ={x: counter0[x] for x in counter0.keys() & set(soft_skills)}\n",
    "    \n",
    "print(bus_occs)\n",
    "print(code_occs)\n",
    "print(knowledge_occs)\n",
    "print(soft_occs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_0 = set(data['job_text_tokenized'][5])\n",
    "vacancy = data['job_text_tokenized'][5]\n",
    "jd_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_0.intersection(bus_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_0.intersection(code_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_0.intersection(soft_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_0.intersection(knowledge_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "for skill in categories:\n",
    "    print(skill, jd_0.intersection(categories[skill]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersects_know = jd_0.intersection(knowledge_skills)\n",
    "intersects_code = jd_0.intersection(code_skills)\n",
    "intersects_soft = jd_0.intersection(soft_skills)\n",
    "intersect_bus = jd_0.intersection(bus_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-novel",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacancy.count('xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-identifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "occsurrences_know ={} \n",
    "for skill in intersects_know:\n",
    "    occsurrences_know[skill] = vacancy.count(skill)\n",
    "occsurrences_know\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "occsurrences_code ={} \n",
    "for skill in intersects_code:\n",
    "    occsurrences_code[skill] = vacancy.count(skill)\n",
    "occsurrences_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "occsurrences_soft ={} \n",
    "for skill in intersects_soft:\n",
    "    occsurrences_soft[skill] = vacancy.count(skill)\n",
    "occsurrences_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "occsurrences_bus ={} \n",
    "for skill in intersects_soft:\n",
    "    occsurrences_bus[skill] = vacancy.count(skill)\n",
    "occsurrences_bus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-green",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categories:\n",
    "    print(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacancy = data['job_text_tokenized'][5]\n",
    "vacancy_set = set(vacancy)\n",
    "matching_skill_per_category = {}\n",
    "\n",
    "for category in categories:\n",
    "    matching_skill_per_category[str(category)]=vacancy_set.intersection(categories[category])\n",
    "#print(matching_skill_per_category)\n",
    "    \n",
    "occ = {}\n",
    "for category in categories:\n",
    "    occ[category] = {}\n",
    "    for s in matching_skill_per_category[str(category)]:\n",
    "        occ[category][s] =  vacancy.count(s)\n",
    "print(occ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['job_text_tokenized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "for vacancy in data['job_text_tokenized'][:3]:\n",
    "    set(vacancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['job_text_tokenized'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vacancy = data['job_text_tokenized'][5]\n",
    "\n",
    "\n",
    "def get_skill_count(vacancy):\n",
    "    # turn the vacancy into a set to compare the words with defined dictionary\n",
    "    vacancy_set = set(vacancy)\n",
    "    # get the matching skills of a job description to the skills defined within different categories of skillsets (tech, bus, softskill...)\n",
    "    matching_skill_per_category = {}\n",
    "    for category in categories:\n",
    "        matching_skill_per_category[str(category)]=vacancy_set.intersection(categories[category])\n",
    "    \n",
    "    #count the occurences of every matching skill\n",
    "    occurrences = {}\n",
    "    for category in categories:\n",
    "        occurrences[category] = {}\n",
    "        for skill in matching_skill_per_category[str(category)]:\n",
    "            occurrences[category][skill] =  vacancy.count(skill)\n",
    "    return occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-accent",
   "metadata": {},
   "outputs": [],
   "source": [
    "requirement = {}\n",
    "for index, vacancy in enumerate(data['job_text_tokenized']):\n",
    "    #print(vacancy)\n",
    "    requirement[index]= get_skill_count(vacancy)\n",
    "    occurence =get_skill_count(vacancy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-diagram",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "#things to do for streamlit\n",
    "\n",
    "# ranking of all skills for streamlit --> agregated view of each categ\n",
    "# percentage of category per job offer (10% bus, 20% tech...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put all vacancies into one huge list\n",
    "all_vacancies=[]\n",
    "for job in data['job_text_tokenized']:\n",
    "    #print(len(job))\n",
    "    all_vacancies = all_vacancies + job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-louisiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_vacancies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacancy_set = set(all_vacancies)\n",
    "len(vacancy_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matching_skill_per_category = {}\n",
    "\n",
    "for category in categories:\n",
    "    matching_skill_per_category[str(category)]=vacancy_set.intersection(categories[category])\n",
    "#print(matching_skill_per_category)\n",
    "occ = {}\n",
    "for category in categories:\n",
    "    occ[category] = {}\n",
    "    for s in matching_skill_per_category[str(category)]:\n",
    "        occ[category][s] =  all_vacancies.count(s)\n",
    "print(occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skill_aggr(all_vacancies):\n",
    "    \n",
    "    vacancy_set = set(all_vacancies)\n",
    "    matching_skill_per_category = {}\n",
    "\n",
    "    for category in categories:\n",
    "        matching_skill_per_category[str(category)]=vacancy_set.intersection(categories[category])\n",
    "    \n",
    "    occ = {}\n",
    "    for category in categories:\n",
    "        occ[category] = {}\n",
    "        for s in matching_skill_per_category[str(category)]:\n",
    "            occ[category][s] =  all_vacancies.count(s)\n",
    "    return occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vacancies=[]\n",
    "for job in data['job_text_tokenized']:\n",
    "    #print(len(job))\n",
    "    all_vacancies = all_vacancies + job\n",
    "total_occurences = get_skill_aggr(all_vacancies)\n",
    "total_occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(total_occurences).reset_index()\n",
    "df= df.rename(columns = {'index':'skill'})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df['business'] >0:\n",
    "    df['category'] = 'business'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in df.columns[1:]:\n",
    "    #print(df[category])\n",
    "    if df.loc[df[category] > 0,:]:\n",
    "              df['category']=category\n",
    "#df.loc[df['a'] > 10, ['a','c']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bus = df[['skill','business']].dropna().sort_values('business', ascending = False).rename(columns = {'business':'count'})\n",
    "df_bus['category']='business'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_know = df[['skill','knowledge']].dropna().sort_values('knowledge', ascending = False).rename(columns = {'knowledge':'count'})\n",
    "df_know['category']='knowledge'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_code = df[['skill','programming']].dropna().sort_values('programming', ascending = False).rename(columns = {'programming':'count'})\n",
    "df_code['category']='programming'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-raleigh",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soft = df[['skill','soft_skills']].dropna().sort_values('soft_skills', ascending = False).rename(columns = {'soft_skills':'count'})\n",
    "df_soft['category']='soft skills'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categ = df_bus.append(df_know).append(df_code).append(df_soft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categ['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = df_categ.nlargest(100, 'count')\n",
    "categs = np.array(df_categ['category'].unique())\n",
    "category = np.insert(categs, 0, 'all')\n",
    "\n",
    "\n",
    "#Dropdownbox\n",
    "input_dropdown = alt.binding_select(options = category)\n",
    "selection = alt.selection_single(fields = ['category'], bind = input_dropdown, name= 'Skill ')\n",
    "\n",
    "alt.Chart(source).mark_bar().encode(\n",
    "x = ('count:Q'),\n",
    "y = alt.Y('skill',sort='-x'),\n",
    ").add_selection(selection).transform_filter(\n",
    "    selection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vega_datasets import data\n",
    "movies = alt.UrlData(\n",
    "    data.movies.url,\n",
    "    format=alt.DataFormat(parse={\"Release_Date\":\"date\"})\n",
    ")\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_json('https://cdn.jsdelivr.net/npm/vega-datasets@v1.29.0/data/movies.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ['G', 'NC-17', 'PG', 'PG-13', 'R']\n",
    "genres = ['Action', 'Adventure', 'Black Comedy', 'Comedy',\n",
    "       'Concert/Performance', 'Documentary', 'Drama', 'Horror', 'Musical',\n",
    "       'Romantic Comedy', 'Thriller/Suspense', 'Western']\n",
    "\n",
    "base = alt.Chart(movies, width=200, height=200).mark_point(filled=True).transform_calculate(\n",
    "    Rounded_IMDB_Rating = \"floor(datum.IMDB_Rating)\",\n",
    "    Hundred_Million_Production =  \"datum.Production_Budget > 100000000.0 ? 100 : 10\",\n",
    "    Release_Year = \"year(datum.Release_Date)\"\n",
    ").transform_filter(\n",
    "    alt.datum.IMDB_Rating > 0\n",
    ").transform_filter(\n",
    "    alt.FieldOneOfPredicate(field='MPAA_Rating', oneOf=ratings)\n",
    ").encode(\n",
    "    x=alt.X('Worldwide_Gross:Q', scale=alt.Scale(domain=(100000,10**9), clamp=True)),\n",
    "    y='IMDB_Rating:Q',\n",
    "    tooltip=\"Title:N\"\n",
    ")\n",
    "\n",
    "genre_dropdown = alt.binding_select(options=genres)\n",
    "genre_select = alt.selection_single(fields=['Major_Genre'], bind=genre_dropdown, name=\"Genre\")\n",
    "\n",
    "filter_genres = base.add_selection(\n",
    "    genre_select\n",
    ").transform_filter(\n",
    "    genre_select\n",
    ").properties(title=\"Dropdown Filtering\")\n",
    "\n",
    "filter_genres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-wells",
   "metadata": {},
   "source": [
    "## Vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-health",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "instanciate a model with the .load method and select the path to the saved .model files\n",
    "'''\n",
    "\n",
    "w2v_model = Word2Vec.load(\"../fydjob/data/models/w2v_model_baseline.model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = ['business', 'dashboard']\n",
    "df_words= pd.DataFrame(w2v_model.wv.most_similar(word), columns=['Similar word', 'distance']) # works with single words\n",
    "df_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fydjob.Word2VecPipeline import WordPipeline\n",
    "\n",
    "model = WordPipeline(\"../fydjob/data/models/w2v_model_baseline.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-galaxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'python'\n",
    "no_rec = 5\n",
    "\n",
    "model.most_similar_skills(word,n_recommendations= no_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-fellow",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
