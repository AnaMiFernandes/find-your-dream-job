{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "empirical-watch",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from fydjob.Database import Database\n",
    "import fydjob.utils as utils\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "separate-meditation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from /home/vlud/code/OWNER_vlad/find-your-dream-job/fydjob/output/nlp_frame.joblib\n",
      "Token columns already found.\n",
      "Processed column already found.\n",
      "Loaded from /home/vlud/code/OWNER_vlad/find-your-dream-job/fydjob/output/nlp_frame.joblib\n"
     ]
    }
   ],
   "source": [
    "from fydjob.NLPFrame import NLPFrame\n",
    "\n",
    "ndf = NLPFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "religious-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ndf.df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "authentic-interstate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [you, are, responsible, for, improvement, of, ...\n",
       "1     [we, are, looking, for, a, senior, software, e...\n",
       "2     [as, a, member, of, the, data, engineering, te...\n",
       "3     [we, are, digittyio, an, international, startu...\n",
       "4     [we, activate, data, for, our, clients, by, us...\n",
       "5     [td, reply, is, an, innovation, and, marketing...\n",
       "6     [the, spirit, of, a, startup, at, one, of, ger...\n",
       "7     [responsibilities, as, senior, data, engineer,...\n",
       "8     [freelancer, projekt, big, data, engineer, pyt...\n",
       "9     [who, we, are, looking, for, we, are, looking,...\n",
       "10    [junior, data, engineer, fmd, all, interviews,...\n",
       "11    [checkout, charlie, is, an, international, pre...\n",
       "12    [about, the, job, as, a, senior, data, enginee...\n",
       "13    [your, position, as, a, data, engineer, mfd, y...\n",
       "14    [overview, this, is, a, fulltime, position, ba...\n",
       "15    [you, see, data, as, the, bloodstream, of, mod...\n",
       "16    [about, the, job, as, a, senior, data, enginee...\n",
       "17    [do, data, and, tech, get, you, pumped, do, yo...\n",
       "18    [pricehubble, is, a, proptech, company, set, t...\n",
       "19    [at, kontist, were, looking, for, a, data, eng...\n",
       "Name: job_text_tokenized, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.job_text_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "equivalent-diversity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-bedc9e3e5dea>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['clean'] = df.job_text_tokenized.apply(utils.lemmatize_words).apply(utils.remove_stopwords)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     [responsible, improvement, taledos, search, ma...\n",
       "1     [looking, senior, software, engineer, extensiv...\n",
       "2     [member, data, engineering, team, responsible,...\n",
       "3     [digittyio, international, startup, headquarte...\n",
       "4     [activate, data, client, using, stateoftheart,...\n",
       "5     [td, reply, innovation, marketing, consultancy...\n",
       "6     [spirit, startup, one, germany, largest, famil...\n",
       "7     [responsibility, senior, data, engineer, mfx, ...\n",
       "8     [freelancer, projekt, big, data, engineer, pyt...\n",
       "9     [looking, looking, solutionoriented, senior, d...\n",
       "10    [junior, data, engineer, fmd, interview, done,...\n",
       "11    [checkout, charlie, international, premium, pu...\n",
       "12    [job, senior, data, engineer, pipeline, orches...\n",
       "13    [position, data, engineer, mfd, help, shape, s...\n",
       "14    [overview, fulltime, position, based, berlin, ...\n",
       "15    [see, data, bloodstream, modern, technology, n...\n",
       "16    [job, senior, data, engineer, pipeline, orches...\n",
       "17    [data, tech, get, pumped, see, data, essential...\n",
       "18    [pricehubble, proptech, company, set, radicall...\n",
       "19    [kontist, looking, data, engineer, dataops, jo...\n",
       "Name: clean, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean'] = df.job_text_tokenized.apply(utils.lemmatize_words).apply(utils.remove_stopwords)\n",
    "df['clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "environmental-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['clean']\n",
    "texts_tagged = [TaggedDocument(text, tags=['tag_'+str(tag)]) for tag, text in enumerate(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "surprising-auditor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "broken-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocabulary with CBOW (dm=0) - instanciate model\n",
    "model_dbow = Doc2Vec(documents=texts_tagged,\n",
    "                     dm=0,\n",
    "                     alpha=0.025,\n",
    "                     vector_size=len(texts_tagged), \n",
    "                     min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "reflected-canyon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 0\n",
      "training epoch 2\n",
      "training epoch 4\n",
      "training epoch 6\n",
      "training epoch 8\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "for epoch in range(10):\n",
    "    if epoch % 2 == 0:\n",
    "        print(f'training epoch {epoch}')\n",
    "    model_dbow.train(texts_tagged, total_examples=model_dbow.corpus_count, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "disturbed-governor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.doc2vec.Doc2Vec at 0x7f51647d6610>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cosmetic-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_jobs(tokenized_job):\n",
    "    ''' input: tokenized job offers \n",
    "        returns tags of top 5 most similar job offers and similarity probabilities\n",
    "    '''\n",
    "    \n",
    "    # infer vector from text\n",
    "    infer_vector = model_dbow.infer_vector(tokenized_job)\n",
    "    # finds similar texts\n",
    "    similar_documents = model_dbow.docvecs.most_similar([infer_vector], topn = 30)\n",
    "    \n",
    "    return similar_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "retained-bishop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tag_0', 0.9975348114967346),\n",
       " ('tag_18', 0.3644728660583496),\n",
       " ('tag_11', 0.35717326402664185),\n",
       " ('tag_13', 0.3562268316745758),\n",
       " ('tag_15', 0.3551161289215088),\n",
       " ('tag_9', 0.35347431898117065),\n",
       " ('tag_7', 0.34985795617103577),\n",
       " ('tag_16', 0.34821438789367676),\n",
       " ('tag_8', 0.3468230366706848),\n",
       " ('tag_5', 0.34655648469924927),\n",
       " ('tag_6', 0.34473031759262085),\n",
       " ('tag_2', 0.34233200550079346),\n",
       " ('tag_12', 0.34160661697387695),\n",
       " ('tag_19', 0.3400558531284332),\n",
       " ('tag_3', 0.333818256855011),\n",
       " ('tag_1', 0.3330245018005371),\n",
       " ('tag_14', 0.32319244742393494),\n",
       " ('tag_10', 0.31951624155044556),\n",
       " ('tag_4', 0.31348657608032227),\n",
       " ('tag_17', 0.3073556125164032)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_jobs(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "manual-bobby",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_text</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>job_info</th>\n",
       "      <th>job_link</th>\n",
       "      <th>query_text</th>\n",
       "      <th>source</th>\n",
       "      <th>tag_language</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist / Matching Engineer (m/w/d)</td>\n",
       "      <td>You are responsible for improvement of Taledo’...</td>\n",
       "      <td>Taledo</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Scientist / Matching Engineer (m/w/d)\\nTa...</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>scrape_json</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Senior Software Engineer - Data Platform</td>\n",
       "      <td>We are looking for a Senior Software Engineer ...</td>\n",
       "      <td>Zalando SE</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Senior Software Engineer - Data Platform\\nZala...</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>scrape_json</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Senior Data Engineer (m/w/t)</td>\n",
       "      <td>As a member of the Data Engineering Team, you ...</td>\n",
       "      <td>Quandoo GmbH</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Senior Data Engineer (m/w/t)\\nQuandoo GmbH17 B...</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>scrape_json</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Data Engineer (w/m/d)</td>\n",
       "      <td>We are digitty.io – an international start-up ...</td>\n",
       "      <td>digitty.io</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Engineer (w/m/d)\\ndigitty.io - Berlin</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>scrape_json</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>We activate data for our clients by using stat...</td>\n",
       "      <td>Gemma Analytics</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Engineer\\nGemma Analytics - Berlin</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>scrape_json</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id                                   job_title  \\\n",
       "0       1  Data Scientist / Matching Engineer (m/w/d)   \n",
       "1       2    Senior Software Engineer - Data Platform   \n",
       "2       3                Senior Data Engineer (m/w/t)   \n",
       "3       4                       Data Engineer (w/m/d)   \n",
       "4       5                               Data Engineer   \n",
       "\n",
       "                                            job_text          company  \\\n",
       "0  You are responsible for improvement of Taledo’...           Taledo   \n",
       "1  We are looking for a Senior Software Engineer ...       Zalando SE   \n",
       "2  As a member of the Data Engineering Team, you ...     Quandoo GmbH   \n",
       "3  We are digitty.io – an international start-up ...       digitty.io   \n",
       "4  We activate data for our clients by using stat...  Gemma Analytics   \n",
       "\n",
       "  location                                           job_info       job_link  \\\n",
       "0   Berlin  Data Scientist / Matching Engineer (m/w/d)\\nTa...  data engineer   \n",
       "1   Berlin  Senior Software Engineer - Data Platform\\nZala...  data engineer   \n",
       "2   Berlin  Senior Data Engineer (m/w/t)\\nQuandoo GmbH17 B...  data engineer   \n",
       "3   Berlin         Data Engineer (w/m/d)\\ndigitty.io - Berlin  data engineer   \n",
       "4   Berlin            Data Engineer\\nGemma Analytics - Berlin  data engineer   \n",
       "\n",
       "    query_text source tag_language reviews  \n",
       "0  scrape_json   None           en    None  \n",
       "1  scrape_json   None           en    None  \n",
       "2  scrape_json   None           en    None  \n",
       "3  scrape_json   None           en    None  \n",
       "4  scrape_json   None           en    None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "comparable-gambling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kaggle_1       5297\n",
       "scrape_json     625\n",
       "Name: query_text, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query_text.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "divided-honey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5922, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-lexington",
   "metadata": {},
   "source": [
    "# Trying a simpler approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "allied-serum",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-87346d64e25e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfydjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLPFrame\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNLPFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mndf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNLPFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/OWNER_vlad/find-your-dream-job/fydjob/NLPFrame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbow_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhome_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_dbow.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dbow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoblib_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/OWNER_vlad/find-your-dream-job/fydjob/NLPFrame.py\u001b[0m in \u001b[0;36mload_dbow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_dbow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbow_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbow_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/fydjob/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    583\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mload_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/fydjob/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             warnings.warn(\"The file '%s' has been generated with a \"\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1208\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1210\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1211\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/fydjob/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload_build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNDArrayWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;31m# Be careful to register our new method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/fydjob/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, unpickler)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpickler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpickler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# Manage array subclass case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/fydjob/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(self, unpickler)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mread_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_read_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mread_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_count\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 data = _read_bytes(unpickler.file_handle,\n\u001b[0m\u001b[1;32m    138\u001b[0m                                    read_size, \"array data\")\n\u001b[1;32m    139\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mread_count\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/fydjob/lib/python3.8/site-packages/joblib/numpy_pickle_utils.py\u001b[0m in \u001b[0;36m_read_bytes\u001b[0;34m(fp, size, error_template)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# done about that.  note that regular files can't be non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from fydjob.NLPFrame import NLPFrame\n",
    "\n",
    "ndf = NLPFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "equivalent-ordinance",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ndf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8b92a7213475>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mndf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ndf' is not defined"
     ]
    }
   ],
   "source": [
    "ndf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-dodge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
